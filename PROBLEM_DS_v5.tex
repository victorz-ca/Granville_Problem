%------------ PREAMBLE ---------------------------

\documentclass[12pt]{article}

\usepackage{lipsum} 
\usepackage[margin=1in, left=1.5in,includefoot]{geometry}

%------------------ Header and Footer
\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhf{}
\fancyhead[R]{\leftmark}
%\fancyhead{header}
%\fancyfoot[R]{ \thepage\ }

%---------------------------------------

\usepackage[latin9]{inputenc}

%\usepackage{anyfontsize}

%\setcounter{secnumdepth}{3}
%\setcounter{tocdepth}{3}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{array}
\usepackage[usenames, dvipsnames]{color}
\usepackage{colortbl}  % This package  \RequirePackage{array,color}

%counters? for 
%\newtheorem{theorem}{Theorem}
\newtheorem*{thm}{Theorem}
\newtheorem*{lmm}{Lemma}
%\newtheorem*{pf}{Proof}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

%\newenvironment{proof}[1][Proof]{\begin{trivlist}
%		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}




\usepackage{graphicx}

\usepackage{hyperref}

\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

%------------------- end of PREAMBLE 

%===================== document
\begin{document}

\title{A controlled random walk with decreasing step-sizes}

\author{Victor D. Zurkowski*}
\date{Dec 31, 2018}

\maketitle

\begin{abstract} 
	A random walk $\{X_n\}_{n \ge 1}\}$ on the line, having steps scaled by $n^{-a}$ ($0 < a <1$) of signs controlled towards $0$ does converge to $0$. The re-scaled walk $Z_n = n^a X_n$ converges in distribution to a random variable $Z$. Unlike the case of walks with identically distributed steps, the distribution of $Z$ is not normal, and depends on the distribution of the steps.  
\end{abstract}


\let\thefootnote\relax\footnotetext{* \textit{ 
		\href{https://www.polymatiks.com//}{Polymatiks}, Toronto, Canada}}

%==================== INTRODUCTION ========================
\begin{section}{A random walk problem}  
\label{sec:intro}
	
\hspace{20pt}Vincent Granville is a data scientist and blogger. In the blog \href{https://www.analyticbridge.datasciencecentral.com/profiles/blogs/interesting-probability-problem-for-serious-geeks/}{"Interesting probability problem for serious geeks"} he poses the following problem: 

 ``Let's start with $X(1)=0$, and define $X(k)$ recursively as folows, for $k>1$:
 $$
	X(k) = \begin{cases*}
		X(k-1) + \frac{U(k)}{k^a} \text{ if $X(k-1) < 0$} \\
		\\
		X(k-1) - \frac{U(k)}{k^a} \text{ if $X(k-1) \ge 0$} 
		\end{cases*} 
$$
and let's define $U(k), Z(k)$ and $Z$ as follows:
\begin{align*}
Z(k) &= k^a \ X(k) &\\
&\ &\\
Z &= \lim_{k \rightarrow \infty} Z(k) &\\
&\ &\\
U(k) &= V(k)^b &
\end{align*}
where the $V(k)$'s are deviates from \textit{independent} uniform variables on $[0,1]$ [...].  

Prove that if $0<a<1$, then $X(k)$ converges to $0$ as $k$ increases. Under the same condition, prove that the limiting distribution $Z$ 
\begin{description}
	\item[$\bullet$ ] always exists,
	\item[$\bullet$ ] always takes values between $-1$ and $+1$, with $\min(Z) = -1$, and $\max(Z) = +1$,
	\item[$\bullet$ ] is symmetric, with mean and median equal to 0
	\item[$\bullet$ ] and does not depend on a, but only on b.'' 
\end{description}  

\  

\  


In the blog, Grandville discusses special cases. In particular, the case with:
\begin{eqnarray} \label{fu_assm1}
&& \{U(k)\}_k \text{ are iid with density }f_U  \\ 
&& \nonumber \\
&& essential \ support \{ f_U \} \subseteq [0,1] \\
&& \nonumber \\
&& \label{ref:f_U} \text{ there is $\epsilon > 0$ such that }
[0, \epsilon] \subset essential \ support \{ f_U \} 
\end{eqnarray}  

\

From formal considerations, Grandville conjectures that $Z$ has density $f_Z$, where $f_Z$ solves the Fredholm integral equation:
\begin{equation} \label{eq:f_Z}
f_Z(z) = \int_{0}^1 \left\{ f_U(x+z) + f_U(x-z) \right\} \ f_Z(x) \ dx .
\end{equation} 

Note that $Z(1)=0$, $Z(2) = -U(2)$, and so $Z(k)$ has density with respect to Lebesgue measure for $k \ge 2$, and the density $f_k$ of $Z(k)$ satisfies:  
$$
f_2(z) = f_U(-z)
$$
and
$$
f_k(z) = \int_{-\infty}^{+\infty} f_{k-1}(x)\ f_U\!\left(  \left(x \left(\frac{k}{k-1}\right)^a - z \right)\ sign(x) \right) \ dx  
$$
for $k > 2$.  

\

\

Using simulations, Grandville found the shape of the limit density for special cases of $f_U$. He proposed an explicit solution to the integral equation ( \ref{eq:f_Z} ), which he verified. He then proposed the form of a solution for the general case. As it turns, Grandville ansatz is correct.

\begin{lmm}{} Let $F_U(z) = \int_{-\infty}^{z} f_U(x) dx$ be the cumulative distribution function of $f_U$. Then
\begin{equation} \label{VGansatz}
f_Z(z) = \frac{1}{2} \cdot \frac{1-F_U(|z|)}{1-\int_{0}^{1} F_U(x) dx}
\end{equation}
solves the integral equation (\ref{eq:f_Z}). 

\end{lmm}

  \begin{proof} By linearity of (\ref{eq:f_Z}), it is enough to show that 
  	$$1-F_U(|z|) = \int_{0}^1 \big( f_U(x+z) + f_U(x-z) \big) \ \big(1 - F_U(x) \big) \ dx.$$ Since both sides of this equation involve even functions of $z$, it is enough to show the equality for $z \ge 0$.  
  	
  	For $z \ge 0$,
  	\begin{align*}
  	& \int_{0}^1 \big( f_U(x+z) + f_U(x-z) \big) \ \big(1 - F_U(x) \big) \ dx &\\
  	&= \int_{0}^1  f_U(x-z) \big(1 - F_U(x) \big) \ dx  + 
  	 \int_{0}^1  f_U(x+z) \big(1 - F_U(x) \big) \ dx &\\  	
  	&= \int_{0}^1  f_U(x-z) \big(1 - F_U(x) \big) \ dx 
  	- \int_{0}^1  \big( 1 - F_U(x+z) \big)^{'} \big(1 - F_U(x) \big) \ dx &\\
  	&= \int_{0}^1  f_U(x-z) \big(1 - F_U(x) \big) \ dx  &\\
  	&\ \ \ \ - \big( 1 - F_U(x+z) \big) \big(1 - F_U(x) \big) \Bigg|_{x=0}^{x=1} 
  	- \int_{0}^1  \big( 1 - F_U(x+z) \big) f_U(x)  \ dx &
  	\end{align*}  
  	
  	But $1-F_U(1)=0$, and $1-F_U(0)=1$, so,  
  	$$
  	- \big( 1 - F_U(x+z) \big) \big(1 - F_U(x) \big) \Bigg|_{x=0}^{x=1} =
  	1 - F_U(z).
  	$$  
  	
  	Also, since $f_U(x) = 0$ for $x \notin [0,1]$, we have:
  	\begin{align*}
  	&\int_{0}^1  \big( 1 - F_U(x+z) \big) f_U(x)  \ dx = \int_{-\infty}^{\infty}  \big( 1 - F_U(x+z) \big) f_U(x)  \ dx &\\
  	&= \int_{-\infty}^{\infty}  \big( 1 - F_U(t) \big) f_U(t-z)  \ dt = \int_0^1  \big( 1 - F_U(t) \big) f_U(t-z)  \ dt &
  	\end{align*}
  	The last equality holds on account of the fact that if $t > 1$, then $1 - F_U(t) = 0$, and if $t<0$, then $f_U(t-z) = 0 $.  
  	
  	
  	Therefore,
  	\begin{align*}
  	& \int_{0}^1 \big( f_U(x+z) + f_U(x-z) \big) \ \big(1 - F_U(x) \big) \ dx &\\
  	&= \int_{0}^1  f_U(x-z) \big(1 - F_U(x) \big) \ dx  &\\
  	&\ \ \ \ + \big( 1 - F_U(z) \big) - \int_0^1  \big( 1 - F_U(t) \big) f_U(t-z)  \ dt &\\
  	&=  1 - F_U(z)  &
  	\end{align*} 
    \end{proof}  


\

\

The next result is a justification of why our later work cannot be restricted to working on a compact interval. Let $W$ be one of the kernels transforming $f_{k-1}$ into $f_k$, i.e. a kernel of the form:
$$
W(x,z) = f_U\!\left(  \left(x \rho - z \right)\ sign(x) \right)
$$
with $\rho \ge 1$. We will write $W_k$ for the kernel with $\rho = (\frac{k}{k-1})^a$, which is used to transform $f_{k-1}$ into $f_k$.  

\begin{lmm}{} Let $M>0,\rho \ge 1$ be such that $M \rho \ge 1$, and assume  $essential \ support \{ f_U \} = [0,1]$.  
	
	For $g \in L^1(\mathbb{R}) + L^{\infty}(\mathbb{R})$, let 
$$
\mathcal{W}(g)(z)=\int_{-\infty}^{+\infty} g(x) f_U\!\left(  \left(x \rho - z \right)\ sign(x) \right) \ dx .
$$
Then if $g$ has compact support, so does $\mathcal{W}(g)$, more precisely:
\begin{itemize}
	\item[a)] If $supp(g) \subseteq [-M,M]$ then $supp(\mathcal{W}(g)) \subseteq [-M \rho,M \rho]$  
	\item[b)] The bounds on the support are tight in the sense that: 
	$$
	\left(-M \rho, M \rho \right) \subseteq \bigcup_{g \in L^1 , supp(g) \subseteq [-M,M]} supp(\mathcal{W}(g))  \subseteq  
	\left[-M \rho, M \rho \right]
	$$
\end{itemize}
\end{lmm} 

\begin{proof} Suppose $W(x,z) \ne 0$ and $|x| \le M$ for some $x, z$.  
	
	If $0 \le x \le M$, then, by definition of $W$ and assumption about the support of $f_U$ we get $0 \le x \rho - z \le 1$, so 
\begin{equation*}
-M \rho \le -1 \le x \rho - 1 \le z \le x \rho \le M \rho
\end{equation*}
so $|z| \le M \rho$. 

If  $ - M \le x < 0$, then a similar argument yields: $0 \le |x| \rho + z \le 1$, so 
\begin{equation*}
-M \rho \le - |x| \rho  \le z \le 1 - |x| \rho \le 1 \le M \rho
\end{equation*}
and again, $|z| \le M \rho$. Therefore, if $supp(g) \subseteq [-M,M]$ then 
$$
\mathcal{W}(g)(z) = \int_{-M}^{M} g(x) W(x,z) \ dx = 0 \text{ for $|z| > M \rho$}
$$ i.e. $supp(\mathcal{W}(g)) \subseteq [-M \rho, M \rho]$.  

\  

Let $ \mathcal{A} = \bigcup_{g \in L^1 , supp(g) \subseteq [-M,M]} supp(\mathcal{W}(g)) $. Part a) shows $\mathcal{A}  \subseteq [-M \rho,M \rho] $. To show the other inclusion, take $g = \delta_r$ (the distribution concentrated at $x=r$), with $r \in (0,M)$. We have 
$$
\mathcal{W}(g)(z) = f_U(r \rho -z) ,
$$
whose support is $[r \rho-1,r \rho]$. By approximating $\delta_r$ under the integral with $g$ in $L^1$, we conclude $(r \rho-1,r \rho) \subseteq \mathcal{A}$. Since this holds for all $r \in (0,M)$, $(-1,M \rho) = \bigcup_{r \in (0,M)} (r \rho-1,r \rho) \subseteq \mathcal{A}$.  

 Next, taking $g=\delta_{-r}$, conclude $(- r \rho, 1 - r \rho) \subseteq \mathcal{A}$, and $(-M \rho,1) =  \bigcup_{r \in [0,M]} (-r \rho, 1 -r \rho) \subseteq \mathcal{A}$. This shows b).
\end{proof}

\ 
\ 
We include the above Lemma to underscore two points that complicates a na\"ive approach to the problem:
\begin{itemize}
\item[i.] There is no bounded interval $[-M,M]$ with $M\ge1$ such that the integral transformations $ g \mapsto \mathcal{W}_k(g)(z) = \int_{-M}^{M} g(x) W_k(x,z) \ dx$,  $( g \in L^1(\mathbb{R})), k = 2, 3, \dots $ map the space of $L^1$ functions supported in $[-M,M]$ to itself. Thus, we cannot fix a bounded interval that contains a priory the support of the family $\{f_k\}_k \ge 1$, and use compactness of integral transformations.  

\item[ii)] For the limiting case (with $k=\infty$) with $\rho = 1$, we get that $\mathcal{W}$ maps $L^1[-M,M]$ (with $M \ge 1$) to itself. We will come back to this point when analyzing the distribution of $Z$.
\end{itemize}


\  
\ 
\ 
There are some unrefereed resources that seem to suggest that because the operator that maps $g \in L^1(\mathbb{R})$ to $$\mathcal{W}(g)(z)=\int_{-\infty}^{+\infty} g(x) f_U\!\left(  \left(x \rho - z \right)\ sign(x) \right) \ dx$$
has an integrand kernel, it must be compact. This is not the case, since the spectrum of $\mathcal{W}$ in $L^1(\mathbb{R})$ is not discrete. We will show this in later sections.    

\  
\ 
\ 


We will show:

\begin{thm} With $X,Z,U,a, f_k$ as above, under assumptions (\ref{ref:f_U}) about the support of $f_U$,
	\begin{itemize}
	\item[a)]  $ \lim_{k \rightarrow \infty} X(k) = 0$ a.s. 
	\item[b)]  $ \overline{ \lim}_{k \rightarrow \infty} |Z(k)| \le 1 $ a.s.
	\item[c)] the solution $f_Z$ to (\ref{eq:f_Z}) given in (\ref{VGansatz}) is unique, i.e.: there is one and only one pdf solution of (\ref{eq:f_Z})
	\item[d)] $ f_k  \rightarrow f_Z$ in $L^1(\mathbb{R})$.
	\item[e)] if $f_U \in L^{p}([0,1])$ for some $p>1$ then there is $k_0 = k_0(p)$ such that $f_k \in L^{\infty}(\mathbb{R})$ for $k \ge k_0$ and 
	$ f_k  \rightarrow f_Z$ in $L^{\infty}(\mathbb{R})$
	\item[f)] $Z(k) \rightarrow_d Z$  (convergence in distribution).
	\end{itemize}
\end{thm}

\end{section}



%===================== CONVERGENCCE OF X and Z ================
\begin{section}{The path $\{X(k)\}_{k\ge1}$ }  


%==================== shtopping times
\begin{subsection}{Stopping times} 
		
\hspace{20pt}Let's consider some stopping times associated to the random path $\{X(k)\}_k\ge1$. By definition,
$$
X(2)=- U(1) <0 
$$ 
so, to get to $X(3)$ we move in the direction towards $0$ by adding a positeve term: 
$$
X(3) = X(2) + \frac{U(3)}{3^a}
$$ 
and keep on adding terms until the path crosses $0$ and changes sign, i.e.:
$$
X(k) = X(2) + \sum_{j=3}^{k} \frac{U(j)}{j^a}
$$
as long as $X(k) < 0$. We will show that eventually, $X(k) \ge 0$, at which time instead of adding, we force the path towards $0$ by subtracting terms until the sign changes again, and so on. We define:
\begin{equation}
T_1 = T(1) = 2
\end{equation}
and for $k>1$, as long as $T(k-1)$ is finite,
\begin{equation} \label{Tk}
T_k = T(k) = \inf\left\{j > T_{k-1} \ \Bigg| \  \sum_{s=1+T_{k-1}}^{j} \frac{U(s)}{s^a} > |X(T_{k-1})|  \   \right\}.
\end{equation}
  Equivalently, as long as these stopping times are finite,
 \begin{align*} \label{Tk}
 T_2 &= T(2) = \text{ first step $j > T_1$ such that $X(j) > 0$} \\
  T_3 &= T(3) = \text{ first step $j > T_2$ such that $X(j) < 0$} \\
  &\dots \\
  T_k &= T(k) = \text{ first step $j > T_{k-1}$ such that $(-1)^k X(j) > 0$ } 
 \end{align*} 
and we have 
\begin{equation} \label{eq:Xj}
X(j) ~=~ X(T_{k}) - (-1)^k \sum_{s=1+T_{k}}^{j} \frac{U(s)}{s^a}
   \text{ for } T_{k} <j\le T_{k+1}
\end{equation}
and
\begin{equation}
sign(X(j)) = (-1)^{k-1} \text{ for $T_{k-1} \le j < T_k$ ($k>2$)}.
\end{equation}

In particular,
\begin{align*}
X(T_k) ~=~ X(T_{k-1}) + (-1)^k \sum_{s=1+T_{k-1}}^{T_k} \frac{U(s)}{s^a}  
~=~ (-1)^{k} \left( \sum_{s=1+T_{k-1}}^{T_k} \frac{U(s)}{s^a} - |X(T_{k-1})| \right)   \\
\end{align*}
and so
\begin{align} \label{eq:XleT}
|X(T_k)| &~=~ \sum_{s=1+T_{k-1}}^{T_k} \frac{U(s)}{s^a} - |X(T_{k-1})| ~=~ \left( \sum_{s=1+T_{k-1}}^{T_k-1} \frac{U(s)}{s^a} - |X(T_{k-1})| \right) +
 \frac{U(T_k)}{{T_k}^a}   \nonumber\\
 &\le \frac{U(T_k)}{{T_k}^a} \le \frac{1}{{T_k}^a}.
\end{align}  

Since $T_1 =2 < T_2 <..$ (and they are integers), 
\begin{align}
T_k \ge k+1 .
\end{align}

\   
\   
\   
\   

Let 
\begin{equation} \label{eq:filter}
\mathcal{F}_k = \sigma \text{-algebra generated by $U(1),...,U(k)$}.
\end{equation}
These $\sigma$-algebras form a filtration $\mathcal{F}_{\!*}$ of the underlying probability space in which $U(1), U(2), \dots$ are defined.

\begin{lemma}
For $k \ge 1$,  $T_k$ is a stopping time of the  filtration $\mathcal{F}_{\!*}$.
\end{lemma}

\begin{proof}
	$T_k$ is the step when the $k^{th}$ sign change occurs, so the event $(T_k \le s)$ is true iff there are $k$ or more sign changes in the sequence $X(1),\dots,X(s)$, which depend on  $U(1),...,U(s)$, i.e.: $(T_k \le s) \in \mathcal{F}_s$.
\end{proof}

	\begin{remark}[Remarks]
	The process $U(1), U(2), \dots$ is (trivially) a stationary Markov process. The strong Markov property applied to this case implies that if $T$ is a stopping time of $\mathcal{F}_{\!*}$, finite a.s, then
	
		\begin{itemize}
			\item[i.] $U(T+1), U(T+2) ,\dots$ are independent i.i.d distributed with the same distirbution as $U(1), U(2) ,\dots$
			\item[ii.] $U(T+1), U(T+2) ,\dots$ are independent of $\mathcal{F}_T$, the filtration stopped at $T$.
		\end{itemize}
	 
	\end{remark}
\end{subsection}


%============== POINTWISE BOUNDS on T_k =======================
\begin{subsection}{Asymptotic properties of the stopping times}

\begin{lemma} \label{lmm:Ts} Let $U(k),X(k),Z(k)$ as in the first section, $T(k)$ as in (\ref{Tk}) , $f_U$ satisfies assumptions (\ref{fu_assm1}) to (\ref{ref:f_U}). Let $\mu = E(U(1)) = \int_{0}^{1} x \ f_U(x) \ dx$. Then,
\begin{itemize}
	\item[i.] For every $j \ge 1$, $T_{j}$ is finite a.s.
	
	\item[ii.] For $j,N \ge 1$, with $\Delta T_{j+1} = T_{j+1} - T_{j}$,
	$$ E\left( \Delta T_{j+1} > N | \mathcal{F}_{T_j}\right) ~\le~
	exp\left( 
	\mu  \frac{(1+T_j)^a}{T_j^a} 
	- \frac{\mu^2 (1+T_j)^a}{2} \sum_{s=1}^{N} \frac{1}{{(s+T_j)}^a}  \right)
	$$
	
	\item[iii.] There is a constant $\gamma > 0$ ($\gamma = 3$ works) such that, regardless of the density $f_U$, $\overline{\lim}_{j \rightarrow \infty } \  \mu^2 
	\frac{(T_{j+1}-T_j)}{ T_j (\frac{\ln j}{j})} \le \gamma $ almost surely.
	
	\item[iv.] $\lim_{j \rightarrow \infty} \frac{T_{j+1} }{T_j} = 1$ a.s.
\end{itemize}
\end{lemma}

\begin{proof}
 We proceed inductively. If $k=1$, then $T_1=2$, and the statement holds trivially. Suppose $T_{j}$ is finite a.s.. Let $P_{j}$ be conditional probability given $\mathcal{F}_{T_j}$. We have 
 $$
 \Delta T_{j+1} = T_{j+1} - T_{j} > k \text{ iff }\\
 \sum_{s=1}^{k} \frac{U(s+T_j)}{{(s+T_j)}^a} \le |X(T_{j})|,
 $$
 therefore, taking conditional probabilities:
 \begin{align*}
 P_j\left( \Delta T_{j+1} > k \right) \le 
 P_j\left( \sum_{s=1}^{k} \frac{U(s+T_j)}{{(s+T_j)}^a} \le |X(T_{j})| \right).
 \end{align*}
 Since $T_j$ and $X(T_j)$ are $\mathcal{F}_{T_j}$ measurable, and $U(T_j+1),\dots$ are iid conditional on $\mathcal{F}_{T_j}$, with the same distribution as $U(1),\dots$, if we apply Markov's inequality we get for any $\lambda > 0$:
 \begin{align*}
&& P_j\left( \sum_{s=1}^{k} \frac{U(s+T_j)}{{(s+T_j)}^a} \le |X(T_{j})| \right) 
 \le e^{\lambda |X(T_{j})|} 
E_j\left\{ e^{-\lambda (\sum_{s=1}^{k} \frac{U(s+T_j)}{{(s+T_j)}^a} ) }    \right\} \\
&& =  e^{\lambda |X(T_{j})|} 
 \prod_{s=1}^{k}  E_j\left\{ e^{-\lambda \frac{U(s+T_j)}{{(s+T_j)}^a}  }    \right\},
 \end{align*}
 where $E_j$ is the conditional expectation given $\mathcal{F}_{T_j}$.  
 
 Then we have
 \begin{align*}
 E_j\left\{ e^{-\lambda \frac{U(s+T_j)}{{(s+T_j)}^a} }  \right\} 
  = e^{-\lambda \frac{\mu}{{(s+T_j)}^a} } 
 E_j\left\{ e^{-\lambda \frac{U(s+T_j)-\mu}{{(s+T_j)}^a} ) } \right\}.  
 \end{align*}
Applying Hoeffding's Lemma to $-\lambda \frac{U(s+T_j)-\mu}{{(s+T_j)}^a}$, which has mean $0$ and is bounded in absolute value by $\frac{\lambda}{{(s+T_j)}^a}$, we get
\begin{align*}
E_j\left\{ e^{-\lambda \frac{U(s+T_j)-\mu}{{(s+T_j)}^a} } \right\} 
\le exp\left(  \frac{1}{2} \frac{\lambda^2}{{(s+T_j)}^{2a} }  \right) . 
\end{align*}  

Therefore:
\begin{align} \label{eq:Hoff}
&& P_j\left( \Delta T_{j+1} > k \right) &~\le~
exp\left( 
\lambda |X(T_{j})| 
-\lambda \mu \sum_{s=1}^{k} \frac{1}{{(s+T_j)}^a}  +
 \frac{\lambda^2}{2} \sum_{s=1}^{k}\frac{1}{{(s+T_j)}^{2a} }  \right) \nonumber \\
&& &~\le~
 exp\left( 
 \lambda \frac{1}{T_j^a} 
 -\lambda \mu \sum_{s=1}^{k} \frac{1}{{(s+T_j)}^a}  +
 \frac{\lambda^2}{2} \sum_{s=1}^{k}\frac{1}{{(s+T_j)}^{2a} }  \right)
\end{align}

First, let's chose $\lambda$ in (\ref{eq:Hoff}) so that 
$$
\frac{\lambda^2}{2} \sum_{s=1}^{k}\frac{1}{{(s+T_j)}^{2a} } \le 
\frac{\lambda \mu}{2} \sum_{s=1}^{k} \frac{1}{{(s+T_j)}^a}  
$$
For example, 
\begin{equation}
\lambda = \mu (1+T_j)^a .
\end{equation}


With this choice, each term in the sums above satisfies the inequality
$$
\lambda \frac{1}{{(s+T_j)}^{2a} } \le \mu \frac{1}{{(s+T_j)}^a}  ,
$$
so we get
\begin{equation} \label{eq:Hoff2}
 P_j\left( \Delta T_{j+1} > k \right) ~\le~
exp\left( 
\mu  \frac{(1+T_j)^a}{T_j^a} 
- \frac{\mu^2 (1+T_j)^a}{2} \sum_{s=1}^{k} \frac{1}{{(s+T_j)}^a}  \right).
\end{equation} This shows part ii).  


Taking limits when $k \rightarrow \infty$,
\begin{equation} 
P_j( \Delta T_{j+1} =+\infty ) = 0,
\end{equation}
and taking unconditional probabilities (averaging over $T_j$):
\begin{equation} 
P( \Delta T_{j+1} =+\infty ) = 0,
\end{equation} 
so $T_{j+1}$ is finite a.s. This completes the induction step to show part i).


\   
\   
\   
Going back to (\ref{eq:Hoff2}), and taking $k$ of the form $k_j ~=~ R \ (1+T_j) \frac{\ln(j)}{j}$, with $R>0$ we have:
\begin{align*}
\sum_{s=1}^{k_j} \frac{1}{{(s+T_j)}^a} &\ge \int_{1}^{k_j+1} \frac{1}{{(x+T_j)}^a} \ dx = \frac{(k_j+1+T_j)^{1-a} - (1+T_j)^{1-a}}{1-a}) \\
&~=~ (1+T_j)^{1-a} \frac{( 1 + R \frac{\ln(j)}{j})^{1-a} - 1}{1-a})  ~=~
(1+T_j)^{1-a} ( R \frac{\ln(j)}{j}) (1+ o(1)) \\
&~\ge~  (1+j)(1+T_j)^{-a} ( R \frac{\ln(j)}{j}) (1+ o(1)) ~=~ 
 (1+T_j)^{-a} R \ln(j) (1+ o(1))
\end{align*}
and so
\begin{align*} 
P_j\left( \Delta T_{j+1} > k_j \right) &~\le~
exp\Big( \mu  (1 + \frac{1}{T_j})^a 
- \frac{\mu^2 }{2} R \ln(j) (1+ o(1))  \Big) \\
&\le exp( \mu  (\frac{3}{2})^a ) 
\frac{1}{ j^{\frac{R\mu^2(1+ o(1)) }{2}} }.
\end{align*} Taking unconditional probabilities:
\begin{equation*} 
P\left( \Delta T_{j+1} > k_j \right) ~\le~
 exp( \mu  (\frac{3}{2})^a ) 
\frac{1}{ j^{\frac{R\mu^2(1+ o(1)) }{2}} }.
\end{equation*}

Adding these inequalities:
\begin{equation} \label{eq:BoCli}
\sum_{j\ge1}  P\left( \Delta T_{j+1} > k_j \right) ~\le~
 \sum_{j\ge1} exp( \mu  (\frac{3}{2})^a ) 
\frac{1}{ j^{\frac{R\mu^2(1+ o(1)) }{2}} } < \infty
\end{equation}
if $R$ is sufficiently large. By Borel-Cantelli, 
\begin{equation} \label{eq:BoCli2}
 P\left( \Delta T_{j+1} > k_j \text{ infinitely often }\right) =0 ,
\end{equation} i.e.: for each particular realization of the process $\{X(k)\}_{k\ge1}$ , there is $N_0$ (depending on the particular realization) such that 
\begin{equation} \label{eq:BoCli3}
\Delta T_{j+1} \le R \ (1+T_j) \frac{\ln(j)}{j} 
\end{equation} 
for $j\ge N_0$ . 
\

\

Going back to (\ref{eq:BoCli}) with $R =  \frac{2}{\mu^2}(1+\epsilon)$ we get:
$$
\overline{\lim}_{j \rightarrow \infty } \ \mu^2 
\frac{(T_{j+1}-T_j)}{ T_j (\frac{\ln j}{j})} \le 3.
$$
This shows iii).

From (\ref{eq:BoCli3}), for $j$ large:
\begin{align*}
0 \le \frac{\Delta T_{j+1} }{T_j} \le R \ (1+\frac{1}{T_j}) \frac{\ln(j)}{j}
\end{align*}
so
\begin{align*}
\lim_{j \rightarrow \infty} \frac{\Delta T_{j+1} }{T_j} = 0. 
\end{align*}
This shows iv).


\end{proof}


\end{subsection}



%============== POINTWISE CONVERGENCE OF X(k), Z(K) ==========

\begin{subsection}{Convergence of $\{X(k)\}_k$ and $\{Z(k)\}_k$}


\begin{lemma} \label{lm:XZ convrgnce}
Let $U(k),X(k),Z(k)$ as in the first section, $T(k)$ as in (\ref{Tk}) , $f_U$ satisfies assumptions (\ref{fu_assm1}) to (\ref{ref:f_U}). Let $\mu = E(U(1)) = \int_{0}^{1} x \ f_U(x) \ dx$. Then,
\begin{itemize}
	\item[i.] $\lim_{j \rightarrow \infty } X(j) = 0$ almost surely
	\item[ii.] $\overline{ \lim}_{j \rightarrow \infty} |Z(j)| \le 1$ almost surely
	\item[iii.] There exists $M_0, \gamma_0, \dots, \gamma_3$ that depend only on $\mu$ and $a$ such that, if $j \ge \gamma_0$, $M \ge M_0$  then
	\begin{equation*}
	P(|Z(j)| \ge M) ~\le~ exp(\gamma_3 - \ M^{(1-a)/a} \ (1+j)^{1-a} \gamma_2  ).
	\end{equation*}
\end{itemize}
\end{lemma}

\begin{proof} Since $X(j) = \frac{Z(j)}{j^a}$, i) follows from ii). To show ii), let $j\ge 2$ and let 
	$$
	k = \text{ number of sign changes in the sequence } X(1),X(2),\dots,X(j-1)
	$$
Since $X(1),X(2),\dots$ changes sign at $T(1),T(2),\dots$, we have 
	$$
	k = \min\{s\ |\ T_s\ge j\} - 1 ,
	$$
so $T_{k} < j \le T_{k+1}$.	 

\  

If $j < T_{k+1}$, then $sign(X(j)) = (-1)^k$ and, as in (\ref{eq:Xj}),
\begin{align*}
X(j) &~=~ X(T_{k}) - (-1)^k \sum_{s=1+T_{k}}^{j} \frac{U(s)}{s^a} \\
  &~=~ (-1)^{k} \left( |X(T_{k})| - \sum_{s=1+T_{k}}^{j} \frac{U(s)}{s^a} \right).
\end{align*}   
and 
\begin{align*}
|X(j)| &~=~ |X(T_{k})| - \sum_{s=1+T_{k}}^{j} \frac{U(s)}{s^a} 
   & ~\le~ |X(T_{k})| \le \max \{|X(T_{k})|, |X(T_{k+1})|\}.
\end{align*}

If $j = T_{k+1}$, then trivially $|X(j)| \le \max \{|X(T_{k})|, |X(T_{k+1})|\}$. 
Whether $j=T_{k+1}$, or $j < T_{k+1}$, we have $|X(j)| \le \max \{|X(T_{k})|, |X(T_{k+1})|\}$. Now apply the bounds in (\ref{eq:XleT}), 

$$
|X(j)| \le 
\max \{ 
		\frac{1}{T_{k}^a} , 
		\frac{1}{T_{k+1}^a} \} 
		= \frac{1}{T_{k}^a} 
$$
and
\begin{equation} \label{eq:ZndTs}
|Z(j)| = j^a|X(j)| \le \frac{j^a}{T_{k}^a} \le \frac{j^a}{T_{k+1}^a} \frac{T_{k+1}^a}{T_{k}^a} \le \frac{T_{k+1}^a}{T_{k}^a}
\end{equation}
From Lemma \ref{lmm:Ts} we have $\lim_{j \rightarrow \infty} \frac{T_{j+1} }{T_j} = 1$ a.s., so
$$
\overline{ \lim}_{j \rightarrow \infty} |Z(j)| \le 1 a.s..
$$ This shows ii).

\   

From ii), we get that $ \lim_{j \rightarrow \infty } P(|Z(j)| \ge M) = 0 $ for any $M > 1$. We want to quantify the rate of convergence to justify the simulation based observation made by Grandville that $\{Z(j)\}_{j \ge 1}$ converges to a distribution supported on $[-1,1]$ at a high rate. The idea is to exploit (\ref{eq:ZndTs}), since 
$$
(|Z(j)| \ge M) \subset ( \frac{T_{k+1}^a}{T_{k}^a} \ge M) = 
 ( \Delta T_{k+1} \ge T_{k}(M^{1/a} -1) ).
$$
Note that $k=k(j)$ is a random variable. It can be used to establish point-wise results, but since $T(k(j))$ is not a stopping time of the filtration (\ref{eq:filter}), we need some extra care when using conditional expectations.

Let $M>1$. For the remainder of the proof, in order to lighten the notation, we will use $\gamma_1, \gamma_2,$ etc. to denote positive constants that depend only on $M, \mu, a$, but not always the same constant from line to line.  

\  

Let $j \ge \gamma_0 > 1$; with $\gamma_0$ to be determined. We have:
\begin{align*}
(|Z(j)| \ge M) &~\subseteq~ \bigcup_{k \ge 1} (|Z(j)| \ge M \text{ and } T_k \le j < T_{k+1}) \\
&~\subseteq~ \bigcup_{k \ge 1} ( \frac{T_{k+1}^a}{T_{k}^a} \ge M \text{ and } T_k \le j < T_{k+1}) \\
&~=~ \bigcup_{k \ge 1} ( \Delta T_{k+1} \ge T_{k}(M^{1/a} -1) \text{ and } T_k \le j < T_{k+1}) \\
&~\subseteq~ \bigcup_{k \ge 1} ( \Delta T_{k+1} > \max\{1, T_{k} \ \Gamma_1, j - T_k\} \text{ and } T_k \le j ) ,
\end{align*}
where $\Gamma_1 = M^{1/a}-2$, and we take $\Gamma_1 > 2$ by requiring $M$ to be large enough. Then
\begin{align*}
P(|Z(j)| \ge M) &~=~ \sum_{k \ge 1} P\big( \Delta T_{k+1} > \max\{T_{k} \ \Gamma_1, j - T_k,1\} \text{ and } T_k \le j \big) \\
&~=~ E\left( \sum_{k \ge 1} P_k\big( \Delta T_{k+1} > \max\{T_{k} \ \Gamma_1, j - T_k, 1\} \text{ and } T_k \le j \big) \right) 
\end{align*}
where  $P_{k}$ is conditional probability given $\mathcal{F}_{T_k}$. The event $(T_k \le j)$ is $\mathcal{F}_{T_k}$-measurable, therefore
\begin{align*}
& P_k\Big( \Delta T_{k+1} \ge \max\{T_{k} \ \Gamma_1, j - T_k,1\} \text{ and } T_k \le j \Big)  &\\
& ~=~ P_k\Big( \Delta T_{k+1} \ge \max\{T_{k} \ \Gamma_1, j - T_k,1\}\Big) I(T_k \le j ) &
\end{align*}

From Lemma \ref{lmm:Ts}, relabeling $T_j$ as $T_k$, and with
 $N = floor(\max\{T_{k} \ \Gamma_1, j - T_k,1\})$:
$$
P_k( \Delta T_{k+1} > N) ~\le~
exp\left( 
\mu  \frac{(1+T_k)^a}{T_k^a} 
- \frac{\mu^2 (1+T_k)^a}{2} \sum_{s=1}^{N} \frac{1}{{(s+T_k)}^a}  \right).
$$
But
\begin{align*}
& \sum_{s=1}^{N} \frac{1}{{(s+T_k)}^a} &
&~\ge~ 
\int_{1}^{N+1} \frac{1}{{(s+T_k)}^a} \ ds ~=~ \frac{ (N + T_k + 1)^{1-a} - (1+T_k)^{1-a} }{1-a}. &
%~\ge~ \gamma_2 (1+T_k)^{1-a}  &
\end{align*}  

\  

If $\max\{T_{k} \ \Gamma_1, j - T_k,1\} = 1$ , then $T_k \ \Gamma_1 \le 1$, and $j \le 1 + T_k \le 1 + 1/\Gamma_1$ which is impossible if $j>>1$. 

\  

If  $\max\{T_{k} \ \Gamma_1, j - T_k,1\} = T_{k} \ \Gamma_1$, then $N = floor(T_k \Gamma_1)$, and  
$$
(N + T_k + 1)^{1-a} - (1+T_k)^{1-a} ~\ge~ \gamma_2 (\Gamma_1+1)^{1-a}(1+T_k)^{1-a}.
$$
Also $ j-T_k \le T_k \ \Gamma_1$, so 
$$
(1+T_k) \ge T_k \ge \frac{1}{1+\Gamma_1}\ j \ge \gamma_3 \ (1+j)
$$
and
$$
 (N + T_k + 1)^{1-a} - (1+T_k)^{1-a} ~\ge~ \gamma_2 (\Gamma_1+1)^{1-a} (1+j)^{1-a} .
$$  

\  


If  $\max\{T_{k} \ \Gamma_1, j - T_k,1\} = j - T_k \ge T_{k} \ \Gamma_1$, then $N=j-T_k$, and 
$$ 
(N + T_k + 1)^{1-a} - (1+T_k)^{1-a} =  (j + 1)^{1-a} - (1+T_k)^{1-a} \ge 
( j + 1)^{1-a} - (1+\frac{j}{1+\Gamma_1})^{1-a} ~\ge~ \gamma_3 (\Gamma_1+1)^{1-a} (1+j)^{1-a} .$$

In any case, regardless of the value of $\max\{T_{k} \ \Gamma_1, j - T_k,1\}$
\begin{align*}
\sum_{s=1}^{N} \frac{1}{{(s+T_k)}^a} ~\ge~ \gamma_2 (\Gamma_1+1)^{1-a} (1+j)^{1-a},
\end{align*}
therefore,
\begin{align}
P_k( \Delta T_{k+1} > N) ~\le~ 
exp\left(  \gamma_1 -  \gamma_2 (1+T_k)^a \ (\Gamma_1+1)^{1-a} (1+j)^{1-a}  \right).
\end{align}  

\  

Since $k \le 1 + T_k$, we have
\begin{align}
P_k( \Delta T_{k+1} > N) ~\le~ 
exp\left(   \gamma_1 -  \gamma_2 k^a \ (\Gamma_1+1)^{1-a} \ (1+j)^{1-a}  \right),
\end{align}
and so (recall $\Gamma_1 + 1 = M^{1/a} -1$):
\begin{align*}
P(|Z(j)| \ge M) &~\le~ E\left( \sum_{k \ge 1} exp\left( 
  \gamma_1 -  \gamma_2 k^a \ M^{(1-a)/a} \ (1+j)^{1-a}  \right) I( T_k \le j ) \right) \\
  &~\le~  \sum_{k \ge 1} exp\left( 
  \gamma_1 -  \gamma_2 k^a \ M^{(1-a)/a} \ (1+j)^{1-a}  \right)  \\
  &~\le~ exp(\gamma_3 - \ M^{(1-a)/a} \ (1+j)^{1-a} \gamma_2  ).
\end{align*} This shows iii).







\end{proof}

\begin{remark}
	
	
In the next section we will show that ${Z(j)}_{j\ge 1}$ converges in probability to a distribution supported on the interval $[-1,1]$. We will show elsewhere that the process ${Z(j)}_{j\ge 1}$ visits the neighbourhoods of any point in $(-1,1)$ infinitely often.  
\end{remark}

\end{subsection}


\end{section}

%========================================================


%========================================================
\begin{section}{The spectrum of $W$ }  
	
	Let $U(k),X(k),Z(k)$ be as in the Introduction, $f_U$ satisfies assumptions.  
	
	\begin{definition} Let $C([A,B])$ be the space of (real valued) continuous functions on $[A,B]$ with the usual $supremum$ norm, and let $C_{_{0\!0}}([A,B]) = \{f \in C([A,B]) | f(A)=f(B) = 0\}$ be the subspace of $C([A,B])$ consisting of those functions that vanish at the boundary of $[A,B]$. 
		
	\  
		
	Let $W_k: C(\mathbb{R}) \longmapsto C(\mathbb{R})$ be defined as
	\begin{equation} \label{eq:Wk}
	W_k(g)(x) = \int_{-\infty}^{+\infty} g(s)\ f_U\!\left(  \left(s \left(\frac{k}{k-1}\right)^a - x \right)\ sign(s) \right) \ ds.
	\end{equation}
	Here $k=3,4,\dots, \infty$.   
	
	We will write $W$ for the limit case $k=\infty$. In this section we go over properties of the spectrum of $W$. Many of the statements apply to more general integral operators. Some are linked to the form of $W$.
	
	\
	
	Since $f_U \in L^1([0,1])$, the integrals in the definition of $W_k$ is convergent, and $W_k$ maps continuous functions into continuous functions. By abuse of notation, we will use $W_k$, $W$ for the restrictions and co-restrictions of these maps to various subspaces; the domains and co-domains should be clear from the context.  
	
	We can extend an element $g \in C_{_{0\!0}}([A,B])$ to an element of $C(\mathbb{R})$ or $C_{_{00}}([A_1,B_1])$ if $[A,B] \subset [A_1,B_1]$ by defining $g$ as $0$ outside $[A,B]$; we will not distinguish $g$ from its extensions.  
	
	The operator $W_k$ is closely related to convolutions. Indeed, we can write
	\begin{align*} 
	W_k(g) &= \int_{-\infty}^{+\infty} g(s)\ f_U\!\left(  \left(s \left(\frac{k}{k-1}\right)^a - x \right)\ sign(s) \right) ds \\
	&= \int_{-\infty}^{0} \left(\frac{k-1}{k}\right)^a g(\left(\frac{k}{k-1}\right)^a s)\ f_U\!\left(  \left(x -s \right)\right) ds 
 \\
	&\ \ \ \  +  \int_{0}^{\infty} \left(\frac{k-1}{k}\right)^a g(\left(\frac{k}{k-1}\right)^a s)\ f_U\!\left(  \left(s - x \right)\right) ds \\
	\end{align*}  
	
	Thus, we can write:
	\begin{equation} \label{eq:Wk_Lp}
	W_k(g) = A_k(g)*f_U + B_k(g)*\mathcal{O}(f_U)
	\end{equation}
	where
	\begin{align*} 
	A_k(g)(s) &= \left(\frac{k-1}{k}\right)^a g(\left(\frac{k}{k-1}\right)^a s) I( s \le 0) \\
	B_k(g)(s) &= \left(\frac{k-1}{k}\right)^a g(\left(\frac{k}{k-1}\right)^a s) I( s \ge 0) \\
	\mathcal{O}(f_U)(s) &= f_U(-s)
	\end{align*}  
	Note that (\ref{eq:Wk_Lp}) can be used to define $W_k$ in $L^p$ spaces.
	
  
\end{definition}

\begin{subsection}{$W$ restricted to $C_{_{0\!0}}([-M,M])$}
	For any $r > 0$, let $B(0,r)$ be the open disc in the complex plane centered at $0$ and of radius $r$.  
	
	\begin{lmm}   $f_U$ satisfies the assumptions in section~\ref{sec:intro}, $W$ as in (\ref{eq:Wk}), $M \ge 1$. Then,
		\begin{itemize}
			\item[i.] $W(C([-M,M])) \subseteq C_{_{0\!0}}([-M,M])$, in particular, $W$ is an endomorphism of $C_{_{0\!0}}([-M,M])$
			\item[ii.] $W: C([-M,M]) \longmapsto C_{_{0\!0}}([-M,M])$ is compact 
			\item[iii.] $W$ is order preserving: if $g \in C(\mathbb{R})$ satisfies $g(x) \ge 0$ for all $x$, then $W(g)(x) \ge 0$ for all $x$ 
			\item[iv.] $\int_{-\infty}^{+\infty} W(g)(x)\ dx = \int_{-\infty}^{+\infty} g(s) \ ds $ for all $g \in L^{\infty}([-M,M])$ ($g$ extended as $0$ outside $[-M.M]$)
			\item[v.] Let $\varphi \in C_{_{0\!0}}([-M,M])$ , $\varphi \in Ker(\mathbb{I} - W)$, then
			    \begin{itemize}
				\item[a.] $|\varphi| \in  Ker(\mathbb{I} - W)$
				\item[b.] $\varphi(-x) \in Ker(\mathbb{I} - W)$
				\item[c.] if $\varphi(0) = 0$ then $\varphi = 0$
				\end{itemize} 
			\item[vi.] The spectrum of $W$ satisfies
			$$
			1 \in spec\left(W\Big|_{C_{_{0\!0}}([-M,M])}   \right) \subset \overline{B(0,1)}
			$$
			
			\item[vii.] (Perron) There is an eigenvector $\phi_1$ of $W$ corresponding to the eigenvalue $1$ such that 
				\begin{itemize}
					\item[a.] $\phi_1(x) \ge 0$
					\item[b.] $\int \phi_1 = 1$
					\item[c.] $1$ is a simple eigenvalue (i.e. of multiplicity 1)
				\end{itemize} 
			Moreover, $\phi_1$ is supported on $[-1,1]$.
			
			\item[viii.]  If $\lambda \in spec\left(W\Big|_{C_{_{0\!0}}([-M,M])}   \right)$, and $|\lambda|=1$ then $\lambda = 1$
			
			\item[ix.] If $1 \le M_1 < M_2$ then 
			$$
			spec(W\Big|_{C_{_{0\!0}}([-M_1,M_1])}) \subseteq 
			spec(W\Big|_{C_{_{0\!0}}([-M_2,M_2])})
			$$
		\end{itemize}	
	\end{lmm}	

\begin{remark} Some comments before going through the proof. Part vii.c) is a consequence of the assumption that $f_U$ doesn't have too many zeros on $[0,\epsilon]$ for some $\epsilon > 0$, as per the assumption ($\ref{ref:f_U}$) about $f_U$. This assumption is needed to ensure simplicity of $1$, and the spectral gap, and it is standard in the context of Perron's theorem. Conceivably, the assumptions on $f_U$ can be relaxed, but without a strong way of identifying the weak limit of $\{Z(k)\}_{k \ge 1}$, one would expect the proof of weak convergence will be more delicate.
\end{remark}

\begin{proof} 
	Most of these are basic facts of integral operators with a stochastic kernel, and we will skip some details.
	\  
	
	\    
	
	If $g \in C([-M,M]$, then, by part a) of the lemma in the introduction, $supp(W(g)) \subseteq [-M,M]$. Since $W(g)$ is continuous everywhere, and vanishes outside [-M.M], by continuity, $W(g)$ vanishes at $\pm M$, i.e. $W(g) \in C_{_{00}}([-M,M])$. This shows i).
	\  
	
	\   

	Part ii) is a standard result of integral operators. 
	
	Part iii) is immediate, since, in case $g$ is non-negative, the integrand in (\ref{eq:Wk}) is non-negative. 
	We encountered W in the context of writing the kernel mapping a probability density to another probability density. Part iv) is basically a re-statement of that fact. 
	\  
	
	\    


	Part iv) can be re-stated as follows. $C_{_{00}}([-M,M])'$, the dual 
	of $C_{_{00}}([-M,M])$ consists of finitely additive measures. By abuse of notation, let $dx$ be the Lebesgue measure on $[-M,M]$, as element of $C_{_{00}}([-M,M])'$ in the canonical way. Then iv) says that $W'(dx) = dx$.  
	\  
	
	\   

	For v.a), let $\varphi = W(\varphi)$. 
	\begin{align*}
&&	|\varphi(x)| &~=~ \left| \int_{-\infty}^{+\infty} \varphi(s)\ f_U\!\left(  \left(s - x \right)\ sign(s) \right) \ ds \right| &\\
&&	&~\le~ 
	  \int_{-\infty}^{+\infty} \left| \varphi(s) \right| \ f_U\!\left(  \left(s - x \right)\ sign(s) \right) \ ds  & \\
&& &~=~ W(|\varphi|)(x)  &
	\end{align*}
Integrating over $x$ and using iv), be get
$$
\int |\varphi| \ dx \le \int W(|\varphi|) \ dx = \int |\varphi| \ dx 
$$	
so the first inequality is an equality, and $|\varphi(x)| = W(|\varphi|)(x)$ a.e., but since both are continuous functions, then theay are equal everywhere.
	\  
\  
  
v.b) follows from a simple change of variables in the integral. 

For part v.c), let $\varphi \in Ker(\mathbb{I} - W)$ be such that $\varphi(0)=0$. Then $\varphi_1(x) = \frac{|\varphi(x)| + |\varphi(-x)|}{2}$ is also in  $Ker(\mathbb{I} - W)$, it is non-negative, symmetric, and vanishes at $0$. Using the definition of $W$ and these properties of $\varphi_1$
$$
0 = \varphi_1(0) = \int_{0}^{1} \varphi_1(s)\ 2 \ f_U\!( s) \ ds.
$$
but $f_U(s)>0$ for almost all points (by the assumption $essential \ support f_U = [0,1]$), therefore $\varphi_1(s)=0$ for $s \in [0,1]$.

Let $A=\sup\{ x \in [0,M]\ | \ \varphi_1(s)=0 for s \in [0,x]\}$. So far we know $1 \le A \le M$. If $A < M$ then 
$$
0 = \varphi_1(A) = \int_{A}^M \left\{ f_U(x+A) + f_U(x-A) \right\} \ \varphi_1(x) \ dx, 
$$
but $f_U(x+A)=0$ for $x>0$, since $A \ge 1$, so
$$
0 = \varphi_1(A) = \int_{A}^M \ f_U(x-A) \ \varphi_1(x) \ dx, 
$$
then $f_U(x-A) \ \varphi_1(x) = $ for all $x \in [A, \min\{1,M\}]$, where  $f_U(x-A) > 0$ almost everywhere, so $\varphi_1(x) = $ for all $x \in [A, \min\{1,M\}]$, which contradicts the definition of $A$. It follows that $A=M$, and $\varphi_1 = 0$ and so $\varphi = 0$.

\  

\  

For part vi), notice that from iv), $W'(dx)=dx$, so $1$ is an eigenvalue of $W'$ with eigenvector $dx$, but $spec(W')=spec(W)$, so $1 \in spec(W)$. 
\  

\ 


If $\lambda \in spec(W)$, $\lambda \ne 0$, then, since $W$ is compact, there is an eigenvector $\psi$ corresponding to $\lambda$, normalized so that $\int |\psi| \ dx = 1$. Then
\begin{align*}
&& |\lambda| &~=~ \left| \lambda \int \psi \ dx \right| = \left| \int W(\psi) \ dx \right| &\\
&& &~\le~  \int \left| W(\psi) \right| \ dx  ~\le~ \int W(|\psi|) \ dx = \int |\psi| \ dx = 1 &
\end{align*}
\

\

For vii), since $1$ is an eigenvalue, it has an eigenvector $\phi$, which we can normalize so that $\int |\phi| \ dx = 1$. By part v), $\phi_1 = |\phi|$ is also an eigenvector corresponding to the eigenvalue $1$.

If $\phi_2$ is another eigenvector corresponding to the eigenvalue 1, then $\phi_2 - \frac{\phi_2(0)}{\phi_1(0)} \phi_1 \in Ker(\mathbb{I} - W)$ and vanishes at 0. By part v.c), $\phi_2 = \frac{\phi_2(0)}{\phi_1(0)} \phi_1$, so $Ker(\mathbb{I} - W) = <\phi_1>$, i.e.: $1$ has geometric multiplicity $1$. 

If $(\mathbb{I} - W)^2 H = 0$, then $(\mathbb{I} - W) H \in Ker(\mathbb{I} - W)$, so $(\mathbb{I} - W) H = \alpha \phi_1$ for some $\alpha$. But $0 = \int (\mathbb{I} - W) H \ dx = \alpha \int \phi_1 \ dx = \alpha $, so $(\mathbb{I} - W) H = 0$. This shows $1$ has algebraic multiplicity $1$.

\

\

For part viii), let $\lambda \in spec(W)$, $|\lambda|=1$, and let $\phi$ be an eigenvector normalized as $\int |\phi| \ dx = 1$. We have
\begin{align*}
|\psi(x)| = \left|W(\psi)(x)\right| \le W(|\psi|)(x) 
\end{align*}
and since $\int |\psi| = 1 = \int W(|\psi|)$, then the inequality is an equality a.e., and $|\psi(x)| \in Ker(\mathbb{I}-W)$, so $|\psi(x)| = \alpha \varphi_1$ for some $\alpha$, and om account of the $L^1$ normalization, $\alpha=1$. We can write  $\psi(x) = \epsilon(x) \varphi_1(x)$ with $\epsilon$ continuous where $\varphi_1(x)>0$, and $|\epsilon(x)| = 1$ for all $x$. Then, for any $x$:
\begin{align*}
\varphi_1(x) &~=~ \overline{\lambda} \ \overline{\epsilon(x)} \ 
\int_{-M}^{M}  \epsilon(s) \ \varphi_1(s) \ f_U\!( (s-x)sign(s) )\ ds &\\
&~=~ 
\int_{-M}^{M}  \overline{\lambda} \ \overline{\epsilon(x)} \ \epsilon(s) \ \varphi_1(s) \ f_U\!( (s-x)sign(s) )\ ds  &\\
 &~\le~ \int_{-M}^{M}  \Re{\Big\{\overline{\lambda} \ \overline{\epsilon(x)} \ \epsilon(s) \Big\} } \ \varphi_1(s) \ f_U\!( (s-x)sign(s) )\ ds  &\\
 &~\le~ \int_{-M}^{M}  \varphi_1(s) \ f_U\!( (s-x)sign(s) )\ ds =  \varphi_1(x) &\\
\end{align*}
so 
$$
\Re{\Big\{\overline{\lambda} \ \overline{\epsilon(x)} \ \epsilon(s) \Big\} } = 1 \text{ where } \varphi_1(s) \ f_U\!( (s-x)sign(s) ) > 0
$$
Taking $x > 0$ small, $s = -x$ , $ \varphi_1(s) \ f_U\!( (s-x)sign(s) ) = \varphi_1(-x) \ f_U\!( 2x ) > 0 $ for a.e. $x$ near $0$, so, for a.e. small $x>0$
\begin{align*}
&& &\Re{\Big\{\overline{\lambda} \ \overline{\epsilon(x)} \ \epsilon(-x) \Big\} } = 1 &\\
&& &\overline{\lambda} \ \overline{\epsilon(x)} \ \epsilon(-x)  ~=~ 1 &\\
&& &\lambda = \epsilon(x) \overline{\epsilon(-x)}. &
\end{align*}
But $\epsilon$ is continuous at $0$, so letting $x \rightarrow +0$, we get  $\lambda = |\epsilon(0)|^2 = 1$

For ix), if $\lambda \ne 0$ is in $spec(W\Big|_{C_{_{00}}([-M_1,M_1])})$, and $\phi$ is a corresponding eigenvalue, then, extending  $\phi$ as $0$ outside $[-M_1,M_1]$ we have:
\begin{align*}
W\Big|_{C_{_{00}}([-M_2,M_2])}(\phi)(x) = \int_{-M_2}^{M_2} \phi(s) f_U\!( (s-x)sign(s)) \ ds \\
= \int_{-M_1}^{M_1} \phi(s) f_U\!( (s-x)sign(s)) \ ds
\end{align*}
because $\phi(s) = 0$ for $|s| \ge M_1$. 

If $|x| \le M_1$ then 
\begin{align*}
 \int_{-M_1}^{M_1} \phi(s) f_U\!( (s-x)sign(s)) \ ds = W\Big|_{C_{_{00}}([-M_1,M_1])}(\phi)(x) = \lambda \ \phi(x)
\end{align*}

If $M_1 < x \le M_2$ then 
\begin{align*}
\int_{-M_1}^{M_1} \phi(s) f_U\!( (s-x)sign(s)) \ ds = 
\int_{0}^{M_1} \phi(-s) f_U\!( s+x) + \phi(s) f_U\!( s-x) \ ds = 0
\end{align*}
because under the integral, $s+x > 0 + M_1 \ge 1$, so $f_U\!(s+x)=0$, and $s-x \le M_1 - x < 0$, so $f_U\!( s-x)=0$. Similarly, the integral is $0$ when $-M_2 \le x < -M_1$. But the extension of $\phi$ is also $0$ at $x$ such that $M_1 < |x| \le M_1$, so 
\begin{align*}
W\Big|_{C_{_{00}}([-M_2,M_2])}(\phi)(x) = \lambda \ \phi(x)
\end{align*} 
for all $x \in [-M_2,M_2]$, hence $\lambda \in spec(W\Big|_{C_{_{00}}([-M_2,M_2])})$\endproof
\end{proof}

\

\

\begin{corollary}{(Spectral gap)} There is $r$, $0 < r < 1$ such that
	$$
	spec(W) \subset \overline{B(0,r)} \cup \{1\} .
	$$ 
\end{corollary}
\begin{proof}
$1$ is the only point of $spec(W)$ at the boundary of $B(0,1)$, and $0$ is the only accumulation point of $spec(W)$.\endproof
\end{proof}
\

\

\end{subsection}

%======================================================
\begin{subsection}{$W$ restricted to $L^1[-M,M]$ }
\label{subsec:L1spec}

$W$ can be extended to several spaces; in particular, if $M \ge 1$, considering that the integral 
$$
\int_{-M}^{M} \int_{-M}^{M} \ |g(s)| \ f_U\!( (s-x)sign(s) )\ ds\ dx
$$
is finite for all $g \in L^1[-M,M]$, we can extend $W$ to $L^1[-M,M]$ as
\begin{align} \label{def:WL1}
W(g)(x) = \int_{-M}^{M} \ g(s) \ f_U\!( (s-x)sign(s) )\ ds
\end{align}
for those $x$ for which the integrand is in $L^1$, i.e.: for a.e. $x$. This defines a map from $L^1[-M,M]$ to itself.  

\

\

We explore the spectrum of the resulting operator. When working in $C_{_{0\!0}}$ we have access to the pointwise definition of $W(g)(x)$. In $L^1$, we will make use of duality. 
\ 

\

 


\begin{lmm} Let $M \ge 1$; let $W$ be defined by (\ref{def:WL1}); let $\phi_1$ be the eigenvector of $W\Big|_{C_{_{0\!0}}([-1,1])} $ corresponding to the eigenvalue $1$, normalized as $\phi_1 \ge 0$, $\int \phi_1 = 1$. Then 
	\begin{itemize}
		\item[i.] $W\Big|_{L^1[-M,M]}$ is compact.
		\item[ii.] There is $r$, $0 < r < 1$ such that
		$$
		spec(W\Big|_{L^1[-M,M]}) \subset \overline{B(0,r)} \cup \{1\}. 
		$$ 
		\item[iii.] $Ker(W\Big|_{L^1[-M,M]} - 1) = <\phi_1>.$
	\end{itemize}
\end{lmm}	

Before going into the proof, let's mention that ii) is the statement of existence of the spectral gap for the Markov operator $W$, and iii) is equivalent to existence and uniqueness of the invariant measure (invariant for the Markov chain defined by $W$). One would expect, given the form of kernel of $W$, that it would be easy to show that if $h \in L^1[-M,M]$ satisfies $W(h) = h$, then $h$ is continuous, and reduce the problem of identifying $h$ to the case of continuous eigenvectors, however, it   


\begin{proof}
	For i), replace $f_U$ by $H \in L^1[0,1]$, $H$ continuous. The operator with $f_U$ replaced by $H$ is compact in $L^1$, and converges (in the operator norm for endomorphisms of $L^1[-M,M]$) to $W$ as $H \longrightarrow f_U$ in $L^1$. So $W$ is compact.  
	\
	
	\
	
For ii), note that
\begin{align*}
spec(W\Big|_{L^1[-M,M]}) &= spec(W^* \Big|_{L^{\infty}[-M,M]}) \subseteq spec(W^* \Big|_{C_{_{00}}([-M,M])^*} ) \\
&= spec(W \Big|_{C_{_{00}}([-M,M])} ) \subset \overline{B(0,r)} \cup \{1\}
\end{align*}
because, respectivly: Schauder's theorem, $L^{\infty}[-M,M]  \subseteq C_{_{00}}([-M,M])^*$, Schauder's theorem again, and the Lemma in the previous section.  
\

\

Let $\lambda \in spec(W\Big|_{L^1[-M,M]})$, $\lambda \ne 0$. From Fredholm theory, $dim(Ker(W-\lambda)) = co-dim(Im(W-\lambda))$, so we can find $h_1,\dots,h_d$ that form a basis of $Ker \left( W\Big|_{L^1[-M,M]} - \lambda \right) $, and:
\begin{align*}
L^1[-M,M] &~=~ <h_1,\dots,h_d> \oplus V  \text{ for some subspace $V$ } \\
L^1[-M,M] &~=~ <\omega_1,\dots,\omega_d> \oplus Im(W - \lambda) \text{ for some }\omega_1,\dots,\omega_d\\
\omega_1,\dots,\omega_d &\text{ are linearly independent} \\
(W - \lambda):V &\longrightarrow Im(W - \lambda) \text{   is an isomorphism}
\end{align*}
Applying Ritz lemma, we can find   $\omega_1,\dots,\omega_d$ in  $C_{_{00}}([-M,M])$.
\

\

Let $\zeta_1,\dots,\zeta_d \in L^1[-M,M]^* = L^{\infty}[-M,M]$ be defined as
\begin{align*}
\zeta_i(\omega_j) &~=~ \delta_{i,j} ~=~ \text{ $1$ if $i=j$, $0$ otherwise} \\
\zeta_i &~=~ 0 \text{ on }Im(W - \lambda).
\end{align*}
The fact that $\zeta_1,\dots,\zeta_d$ are continuous on $L^1[-M,M]$ follows from the decomposition of $L^1$. 
Note that 
\begin{align*}
0 &~=~ <\zeta_i, h> \text{ for all } h \in Im(W - \lambda) &\\
\text{ iff } 
0 &~=~ <\zeta_i, (W-\lambda)(g)> \text{ for all } g \in L^1[-M,M] &\\
\text{ iff } 
0 &~=~ <(W^*-\lambda)\zeta_i, g> \text{ for all } g \in L^1[-M,M] &\\
\text{ iff } 0 &~=~ (W^*-\lambda)\zeta_i   &\\
\text{ iff } \zeta_i &\in Ker(W^*\Big|_{L^{\infty}}-\lambda)   &\\
\end{align*}

Note that the inclusion map $\iota: C_{_{00}}([-1,1]) \longrightarrow L^1[-M,M]$ implies a dual inclusion map $\iota^*: L^1[-M,M]^*  \longrightarrow C_{_{00}}([-1,1])^*$, so (identifying elemnts of $L^1[-M,M]^*$ with their images under $\iota^*$), we can consider $\zeta_1,\dots,\zeta_d$ as elements of $C_{_{00}}([-1,1])^*$. Also, (ignoring $\iota^*$ in the notation) $\zeta_1,\dots,\zeta_d \in Ker\left( W^*\Big|_{C_{_{00}}([-M,M])^*} - \lambda \right)$.

$\zeta_1,\dots,\zeta_d $ are linearly independent in $C_{_{00}}([-M,M])^*$, because, if for some scalars $\alpha_1,...$ we have
$$
0 = \sum_i \alpha_i \ \zeta_i \text{ in } C_{_{00}}([-M,M])^*
$$
then evaluating $0$ and $\sum_i \alpha_i \ \zeta_i$ at $\omega_j \in C_{_{00}}([-M,M])^*$, we get $0 = \alpha_j$. In particular:
\begin{align*}
d &= dim \left( Ker \left( W\Big|_{L^1[-M,M]} - \lambda \right) \right) 
= dim \left( Ker \left( W^* \Big|_{L^{\infty}[-M,M]} - \lambda \right) \right)  &\\
&\le dim \left( Ker \left( W^* \Big|_{C_{_{00}}([-M,M])^*} - \lambda \right) \right) 
= dim \left( Ker \left( W\Big|_{C_{_{00}}([-M,M])} - \lambda \right) \right). &
\end{align*}

We apply this inequality to the case $\lambda = 1$, which is in $spec\left( W\Big|_{L^1[-M,M]} - 1 \right)$, and for which we know simplicity of eigenvalue $1$ to get
\begin{align*}
1 &\le dim \left( Ker \left( W\Big|_{L^1[-M,M]} - 1 \right) \right)  &\\
&\le dim \left( Ker \left( W\Big|_{C_{_{00}}([-M,M])} - 1 \right) \right) = 1 &
\end{align*}
Therefore, since $\phi_1 \in Ker \left( W\Big|_{L^1[-M,M]} - 1 \right)$, iii) follows.
\end{proof}



\end{subsection}

\  
\  



\begin{subsection}{$W$ on $C_{_{0\!0}}(\mathbb{R})$ and $L^1(\mathbb{R})$} \label{W_whole_R}
There are some un-refereed sources that seem to suggest that, because $W$ is an integral operator involving a compactly supported function, then it is automatically compact. $W$ is close to a convolution operator, and so it cannot be compact when acting on the entire line. It turns out that part of the range of the Fourier transform of $f_U$ is contained in the spectrum of $W$. To settle any doubt, we include the result in this section.  

\  
\  

Since $f_U$ has compact support, the Fourier transform of $f_U$ given by $\hat{f}_U(z) = \int_0^1 e^{-2 \pi i z s} f_u(s) \ ds$, is an entire function of $z \in \mathbb{C}$. For $\xi \in \mathbb{R}$, small:
\begin{align*}
\hat{f}_U(\xi) &= \int_0^1 (1 - 2 \pi i \xi s - 2 \pi^2 \xi^2 s^2 + \dots) f_u(s) \ ds \\
&= 1 - 2 \pi i \xi \mu - 2 \pi^2 \xi^2 (\mu^2 + \sigma^2) + \dots
\end{align*}
so the parabola $x = 1 - \frac{1}{2} \left( \frac{\mu^2 + \sigma^2}{\mu^2} \right) y^2$ osculates the curve $\hat{f}_U(\mathbb{R})$ at $x=1$, $y=0$. In particular, the range of $\hat{f}_U$ has lots of points (it is not discrete). 

\  
\  

The fact that $supp(f_U) \subseteq [0,\infty)$ implies that $|\hat{f}_U(z)| \le 1$ if the imaginary part of $z$ satisfies $\Im(z) \le 0$.  

\  
\  

\begin{lmm}  Let $W$ as in (\ref{eq:Wk}), i.e.:
	\begin{equation*}
	W(g)(x) = \int_{-\infty}^{+\infty} g(s)\ f_U\!\left(  \left(s - x \right)\ sign(s) \right) \ ds.
	\end{equation*}
 where the we take $g \in  L^1(\mathbb{R}) + L^{\infty}(\mathbb{R})$. Let $\phi_1$ be the eigenvector of $W$ in $C_{_{0\!0}}([-1,1])$ corresponding to the eigenvalue $1$, normalized so that $\phi_1 \ge 0$, $\int \phi_1 = 1$. Let $\mathbb{C}^- = \{z \in \mathbb{C}| \Im(z) \le 0 \}$ be the closed lower half complex plane. Then:
	\item[i.]  $W: C(\mathbb{R}) \longmapsto C(\mathbb{R})$ is not compact
	
	\item[ii.] $\hat{f}_U(\mathbb{C}^-) \subseteq spec\left(W\Big|_{C(\mathbb{R})}  \right)$
	
	\item[iii.]  $W: C_{_{0\!0}}(\mathbb{R}) \longmapsto C_{_{0\!0}}(\mathbb{R}) $ is not compact
	
	\item[iv.]  $W: L^1(\mathbb{R}) \longmapsto L^1(\mathbb{R}) $ is not compact
	
	\item[v.] $\hat{f}_U(\mathbb{C}^-) \subseteq spec(W\Big|_{L^1(\mathbb{R})}) $

	\item[vi.] $ Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) = <\phi_1>$, and $1$ has algebraic multiplicity $1$ as eigenvalue of $W\Big|_{L^1(\mathbb{R})}$.
\end{lmm}
\  

\begin{proof} 
Let $M \ge 2$, $z \in \mathbb{C}^-$. Let 
$$
A_M(x)=
\begin{cases}
1  & \text{if } |x| \le M \\
0  & \text{if } |x| \ge M +1\\
piecewise \  linear & \text{in between}
\end{cases} 
$$ 
and $g_M(x) = e^{-2 \pi i |x| z} A_M(x)$. We have  
\begin{align*}
W(g_M)(x) &= \int_{-M-1}^{M+1} e^{-2 \pi i |s| z} A_M(s) \ f_U\!\left(  \left(s - x \right)\ sign(s) \right) \ ds \\
		&= \int_0^{M+1} e^{-2 \pi i s z} A_M(s) 
		\Big( f_U\!(  s - x ) + f_U\!(  s + x ) \Big) \ ds = W(g_M)(-x),
\end{align*} 
i.e.: $W(g_M)$ is even.  


Since $g_M$ is supported on $[-M-1,M+1]$, then $W(g_M)(x) = 0 = \hat{f}_U(z) g_M(x) $ when $|x| \ge M+1$.  

If $1 \le x \le M -1 $, then $f_U\!(  s + x ) = 0$ for any $s \ge 0$, and so
\begin{align*}
W(g_M)(x) &= \int_0^{M+1} e^{-2 \pi i s z} A_M(s) f_U\!(  s - x )  \ ds \\
 & = \int_{-x}^{M+1 - x} e^{-2 \pi i (s+x) z} A_M(s+x) f_U\!(  s  )  \ ds \\
 & = e^{-2 \pi i x z} \int_0^1 e^{-2 \pi i s z} A_M(s+x) f_U\!(  s  )  \ ds,
\end{align*}
but, in the integrand, $s+x \le 1 + M-1=M$, so $A_M(s+x)=1$, and
$$
W(g_M)(x) = e^{-2 \pi i x z} \int_0^1 e^{-2 \pi i s z} f_U\!(  s  )  \ ds 
= e^{-2 \pi i x z} \hat{f_U}(z) = \hat{f}_U(z) g_M(x).
$$
Therefore
$$
W(g_M)(x) - \hat{f}_U(z) g_M(x) = 0
$$
if $1 \le x \le M-1$. Since $W(g_M)$ and $g_M$ are even, it follows that $W(g_M)(x) - \hat{f}_U(z) g_M(x) = 0 $
if $1 \le |x| \le M-1$ or $M+1 \le |x|$. In any case, $|W(g_M)(x) - \hat{f}_U(z) g_M(x)| \le 2$ for all $x$.  

\  
\  


$i$ follows from $ii$, since compact operators have discrete spectra, and $\hat{f}_U(\mathbb{C}^-)$ is not discrete.

To show $ii$, let $z \in \mathbb{C}^-$.  

If $\hat{f}_U(z) \in spec\left(W\Big|_{C_{_{0\!0}}([-1,1])}   \right) $  then there is $\rho \in C_{_0\!0}([-1,1]) \subset C(\mathbb{R})$, $\rho \ne 0$, such that $(W - \hat{f}_U(z))(\rho) = 0$. Thus, $\hat{f}_U(z) \in spec\left(W\Big|_{C(\mathbb{R})}   \right) $. 

If $\hat{f}_U(z) \notin spec\left(W\Big|_{C_{_{0\!0}}([-1,1])}   \right) $. Taking $g(x) = e^{-2 \pi i |x| z}$, which is in $C(\mathbb{R})$, and applying the previous computation letting $M \leftarrow \infty$, we get $\Delta_z = W(g) - \hat{f}_U(z)g$ is in $C_{_0\!0}([-1,1])$, and since $\hat{f}_U(z) \notin spec\left(W\Big|_{C_{_{0\!0} }([-1,1])}   \right) $, we can write $\Delta_z = (W - \hat{f}_U(z))(\rho_z) $ for some $\rho_z \in C_{_0\!0}([-1,1])$, then
$$
(W - \hat{f}_U(z))(g - \rho_z) = 0
$$
and $g - \rho_z \ne 0$, since $\rho_z$ has compact support and $g$ does not. This shows $\hat{f}_U(z) \in spec\left(W\Big|_{C(\mathbb{R})}   \right) $.  

If $z_o \in \mathbb{C}^-$ and $\hat{f}_U(z_o) \ne 0$ is in $spec\left(W\Big|_{C_{_0\!0}([-1,1])}   \right) $,  using the analyticity of $\hat{f}_U$ and the discreteness of $spec\left(W\Big|_{C_{_0\!0}([-1,1])}   \right) $ away from $0$ , we can find a sequence ${z_j}$ in $\mathbb{C}^-$ such that $z_j \leftarrow z_o$, $\hat{f}_U(z_j) \notin spec\left(W\Big|_{C_{_0\!0}([-1,1])}   \right) $, hence, from our previous result, $\hat{f}_U(z_j) \in spec\left(W\Big|_{C(\mathbb{R})}   \right) $, so passing to the limit, $\hat{f}_U(z_o) \in spec\left(W\Big|_{C(\mathbb{R})}   \right) $. $0$ is an accumulation point of $\hat{f}_U\Big|_{\mathbb{R}}$, so it is in $spec\left(W\Big|_{C_{_0\!0}([-1,1])}   \right) $, which cover the case $\hat{f}_U(z_o) = 0$.  

\  
\  

To show $iii$, assume $W: C_{_{0\!0}}(\mathbb{R}) \longmapsto C_{_{0\!0}}(\mathbb{R}) $ is compact. Pick any $z$ such that $\hat{f}_U(z) \ne 0$. Since the sequence  $\{g_M | M=2,3,...\}$ is contained in $ C_{_0\!0}(\mathbb{R})$ and it is bounded, the sequence $\{W(g_M) | M=2,3,...\}$ would contained a convergent subsequence. Any accumulation point $G$ of $\{W(g_M)\}$ is of the form $G(x) =  e^{-2 \pi i |x| \xi} \hat{f_U}(z) $ for $1 \le |x|$, hence not in $ C_{_0\!0}(\mathbb{R})$, a contradiction. 

\  
\  
$iv$ follows from $v$, because compact operators have discrete spectrum, and $\hat{f}_U(\mathbb{C}^-)$ is not discrete.  

\  
\  

To show $v$, let $\Im(z)<0$, and such that $\hat{f}_U(z) \ne 0$. In part $ii$ we showed that there is an eigenvector of $W$ in $C(\mathbb{R})$ of the form $V(x) = e^{-2 \pi i |x| z} - \rho_z(x)$ with $\rho_z \in C_{_0\!0}([-1,1])$, therefore $V$ is integrable, so $\hat{f}_U(z) \in spec(W\Big|_{L^1(\mathbb{R})}) $. By continuity we get $\hat{f}_U(\mathbb{C}^-) \subseteq spec(W\Big|_{L^1(\mathbb{R})}) $.  

\  
\  

To show $vi$, recall $\phi_1$ is continuous and is supported on $[-1,1]$, so $\phi_1 \in L^1(\mathbb{R})$, which shows the inclusion $ <\phi_1> \subseteq Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) $.

For the other inclusion, let $g \in Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) $, $g \ne 0$. We will show that $g$ has compact support, then, applying the result of section (\ref{subsec:L1spec}) we conclude $g \in <\phi_1>$. If
\begin{equation} \label{eq:1eigen_g}
g(x) = \int_{-\infty}^{+\infty} g(s) \ f_U\!\Big( (s-x)sign(s) \Big) \ ds
\end{equation}
(in $L^1(\mathbb{R})$) then
\begin{equation} \label{eq:abs_g}
|g(x)| \le \int_{-\infty}^{+\infty} |g(s)| \ f_U\!\Big( (s-x)sign(s) \Big) \ ds
\end{equation}
and since both sides have the same integral over $\mathbb{R}$ we conclude that equality holds in (\ref{eq:abs_g}) a.e., so $|g| \in Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) $. Let $G(x) = |g(x)| + |g(-x)|$, then $G \in Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) $, $G \ge 0$, $G \ne 0$, and $G$ is even. Moreover, $G$ has compact support iff $g$ has compact support, so we can work with $G$. 

Let $V(a) = \int_{a}^{+\infty} G(x) \ dx$. Since $G$ is non-negative and integrable, $V$ is continuous and non-increasing. We claim that $V(a) = V(1)$ for all $a \ge 1$. Indeed, given $a \ge 1$,
\begin{align*}
\int_{a}^{+\infty} G(x) \ dx = 
\int_{a}^{+\infty} \int_{0}^{+\infty} G(s) \ \Big[ f_U(s-x) + f_U(s+x) \Big] \ ds \ dx
\end{align*}
But if $x \ge a \ge 1$ and $u \ge 0$, then $f_U(s+x) = 0$, so
\begin{align*}
&\int_{a}^{+\infty} G(x) \ dx = 
\int_{a}^{+\infty} \int_{0}^{+\infty} G(s) \  f_U(s-x)  \ ds \ dx \\
&=\int_{a}^{+\infty} \int_{-x}^{+\infty}  G(h+x) \ f_U(h)  \ dh \ dx \\
&=\int_{a}^{+\infty} \int_{0}^{1}  G(h+x) \ f_U(h)  \ dh \ dx \\
&=\int_{0}^{1} f_U(h) \int_{a}^{+\infty}  G(h+x) \ dx \ dh =
\int_{0}^{1} f_U(h) \int_{a+h}^{+\infty}  G(x) \ dx \ dh \\
& \le \int_{0}^{1} f_U(h) \int_{a}^{+\infty}  G(x) \ dx \ dh = \int_{a}^{+\infty}  G(x) \ dx
\end{align*}
therefore, the above inequality is an equality, and we get
$$
\int_{a+h}^{+\infty}  G(x) \ dx =  \int_{a}^{+\infty}  G(x) \ dx 
$$
a.e. $h \in [0,1]$ with respect to the measure $f_U \ dh$, in particular,
$$
V(a+h) = V(a) 
$$
for some $h > 0$. Applying this result to $a=1$ and using the monotonicity of $V$, we conclude that $V(1)=V(1+h)$ for all $h \in [0,\epsilon)$ for some $\epsilon > 0$.  

If $V(a) < V(1)$ for some $a>1$, take $a_0 = \inf \{a > 1| V(a) < V(1)\} $ and apply the result to $a_0$. We have $V(1) = V(a_0) $, and so $V(1)= V(a_0 + h)$ for all small $h > 0$, but also, $V(a) < V(1)$ for some points $a > a_0$. A contradiction.

Since $\lim_{a \rightarrow \infty } V(a) = 0$, we conclude $V(1)=0$, and $G$ is supported on $[-1,1]$, which completes the proof of $ Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) = <\phi_1>$.  

We can show that $1$ is an algebraically simple eigenvalue of $W\Big|_{L^1(\mathbb{R})}$ as before, because is $h \in L^1(\mathbb{R})$ satisfies $ (W -1)^2(h) = 0$, then $g = (W-1)(h) \in Ker\left( W\Big|_{L^1(\mathbb{R})} - 1 \right) = <\phi_1>$, so $(W-1)(h) = g = \lambda \phi_1$ for some constant $\lambda$. Integrating over $\mathbb{R}$ we get $0 = \int (W-1)(h) =  \lambda \int \phi_1 = \lambda $, hence $(W-1)(h) = 0$. This completes the proof of $vi$.
\end{proof}

\end{subsection}

\  
\  


\begin{subsection}{Iterates of $W$ on $C_{_{0\!0}}([-M,M])$ and $L^1[-M,M]$ }  \label{W_on_cpct}

\hspace{20pt}We want to make parallel statements about $W$ acting on $C_{_{0\!0}}([-M,M])$ and on $L^1[-M,M]$. We describe decompositions of these spaces that are akin to an invariant manifold description of the dynamics generated by iterates of $W$. 
 
\


\begin{lemma} \label{lmm:iters}
Let $\varphi_1$ be the eigenfunction of $C_{_{0\!0}}([-1,1])$ that is non-negative, normalized so that $\int \varphi_1 \ ds =1$. Let $M>1$. For $\mathbb{B}$ either of $C_{_{0\!0}}([-M,M])$ or $L^1[-M,M]$, let $S_1 = <\varphi_1>$ be the one-dimensional space spanned by $\varphi_1$ in $\mathbb{B}$ and let $S_2 = Ker( dx) = \{g \in \mathbb{B} \ | \int_{-M}^{M} g \  dx = 0 \} $. Then
\begin{itemize}
	\item[i.] $S_1$, $S_2$, $C_{_{00}}([-M_0,M_0]$ with $1 \le M_0 < M$ are invariant subspaces of $W$
	\item[ii.] $\mathbb{B}$ is isomorphic to the direct sum $<\varphi_1> \oplus Ker( dx)$
	\item[iii.] There is $r$ , $ 0 < r < 1$ such that 
	$$
	spec(W\Big|_{S_2}) \subset \overline{B(0,r)}
	$$
	\item[iv.] There is a norm $\mathpzc{N}$ on $\mathbb{B}$, equivalent to the standard norm in $\mathbb{B}$, such that $W\Big|_{S_2}$ is a contraction 
\end{itemize}
\end{lemma}


\begin{proof} Part i) follows from the facts that $\phi_1$ is an eigenvalue, $W$ preserves integrals, and $W$ does not increase the support of elements in $C_{_{00}}([-M_0,M_0]$.  
	
Let
\begin{align*}
\pi_1:\mathbb{B} \longmapsto S_1 \\
\pi_1(g) = (\int g \varphi_1) \ \varphi_1
\end{align*}
and
\begin{align*}
\pi_2:\mathbb{B} \longmapsto S_2 \\
\pi_2(g) = g - (\int g \varphi_1) \ \varphi_1.
\end{align*}
The map $\pi_1 \oplus \pi_2$ is (well defined), linear, continuous (giving $S_1$, $S_2$ the metric induced by the norm in $\mathbb{B}$), invertible. This shows ii).  

For iii, $spec(W\Big|_{S_2})$ is compact, so, with the possible exception of $0$, the spectrum coincides with the point spectrum, eigenvectors of $W\Big|_{S_2}$ are eigenvectors of $W$, so $spec(W\Big|_{S_2}) \subseteq spec(W) \subseteq \{1\} \cup \overline{B(0,r)}$; but $1 \notin spec(W\Big|_{S_2})$, else "the" eigenvector of $W$ corresponding to $1$ would be in $S_2$, hence 
$$
spec(W\Big|_{S_2}) \subseteq \overline{B(0,r)}.
$$

For part iv), let $\mathcal{W} = W|_{S_2}$, which is an endomorphism of $S_2$. By part iii), The map $(\mathbb{I} - z \mathcal{W})$ is invertible for $|z| < 1/r$,  so $(\mathbb{I} - z \mathcal{W})|_{S_2}^{-1} = \sum_{j \ge 0} z^j \mathcal{W}^j$ converges for $|z| < 1/r$. In particular:
$$
\overline{\lim}_{n \rightarrow \infty} \| \mathcal{W}^n\|^{1/n} \le r
$$ 
where $\| \ \|$ is the operator norm for automorphisms of $\mathbb{B}$ restricted and co-restricted to $S_2$. Therefore, if $r_1$ satisfies $r < r_1 < 1$, there is $B$ such that $\| \mathcal{W}^n \| \le B \ r_1^n$, and there is $z$ such that $ r_1 < z < 1$.  

Let if $\phi \in \mathbb{B}$. Write $\phi = \alpha \varphi_1 + g$ with $g \in S_2$. Consider 
$$
\mathpzc{N}(\phi) =: |\alpha| \| \varphi_1 \| + \sum_{j \ge 0} z^{-j} \| \mathcal{W}^j g\|. 
$$
Since 
\begin{align*}
\sum_{j \ge 0} z^{-j} \| \mathcal{W}^j g\| 
~\le~ \sum_{j \ge 0} z^{-j} \| \mathcal{W}^j \| \ \|g\|  
~\le~ \sum_{j \ge 0} z^{-j} B r_1^j \ \|g\| = \frac{B}{1 - \frac{r_1}{z} } \|g\|
~<~ \infty,
\end{align*}
the series in the definition of $\mathpzc{N}(\phi)$ is convergent.

$\| g \| = z^{-j} \| \mathcal{W}^j \ g\| \Big|_{j=0} \le \mathpzc{N}(g)$, form where it follows that $\mathpzc{N}$ is equivalent to the norm $\| \|$.  

$\mathpzc{N}$ satisfies the properties of a norm.   

Finally,
$$
\mathpzc{N}(\mathcal{W}(g)) 
~=~ \sum_{j \ge 0} z^{-j} \| \mathcal{W}^{j+1} g\|
~=~ z \ \sum_{j \ge 1} z^{-j} \| \mathcal{W}^{j} g\|
~\le~ z \mathpzc{N}(g).
$$
Since $ z < 1$, we get that $\mathcal{W}$ restricted to $S_2$ is a contraction.  
\end{proof}
	
	
\end{subsection}


		
\end{section}

%========================================================
% Weak convergence of Z_k
%========================================================

\begin{section}{Weak convergence of $\{Z(j)\}_{j \ge 1}$ }

In this section we complete the proof of the Theorem stated in the Section \ref{sec:intro}. Parts $a)$, $b)$ are dealt with in Lemma \ref{lm:XZ convrgnce}. Part $c)$ is proved in Section \ref{W_whole_R}.  

\  

\begin{lemma}
	Part $d$ of the Theorem stated in the Section \ref{sec:intro} holds.
\end{lemma}

\begin{proof} To show $d)$, i.e.: $ f_k  \rightarrow f_Z$ in $L^1(\mathbb{R})$, first choose $M_0 > 2$ as in Lemma \ref{lm:XZ convrgnce}, so that the tail probabilities of $Z_j$ are suitably bounded for $j$ sufficiently large. By modifying $\gamma_2$ and $\gamma_3$ we may have that there are constants $C$, $\gamma_2$ that depend only on $\mu$ and $a$ such that:
$$
P( |Z(j)| \ge M) \le C\ exp( - \gamma_2 M^{(1-a)/a} j^{1-a} )
$$
for $M \ge M_0$ and $j \ge 1$.  

\  

For such value $M_0$, by the result in section \ref{W_on_cpct}, there is a norm $\mathpzc{N}$ on $L^1[-M_0,M_0]$ that is equivalent to the standard $L^1$ norm under which the operator $W$ restricted to a suitable subspace is a contraction. Explicitly, there is $\lambda \in (0,1)$ such that for any $g \in L^1[-M_0,M_0]$, if $\int g(x)dx = 0$, then $\mathpzc{N}(W(g)) \le \lambda \mathpzc{N}(g).$   	
	   
Let us consider the following modification of the operator $W_k$ defined in (\ref{eq:Wk}). To lighten the notation, let $K_k(x,s)= f_U\!\left(  \left(s \left(\frac{k}{k-1}\right)^a - z \right)\ sign(s) \right)$. For $g \in L^1[-M_0,M_0]$, define $V_k(g)$ as:
$$
V_k(g)(z) = \left\{ 
\begin{aligned}
& \int_{-\infty}^{+\infty} g(s) K_k(x,s) ds  &\text{ if }|z| \le M_0  &\\
& 0 &\text{ if }|z| > M_0  &
\end{aligned}
\right.
$$

We claim that $V_k \rightarrow W$ as operators on $L^1[-M_0,M_0]$. Indeed, if $g \in L^1[-M_0,M_0]$, then for $z \in [-M_0,M_0]$,
$$
V_k(g)(z) - W(g)(z) = \int_{|x| \le M_0} g(x) \big[ K_k(x,s) - K_{\infty}(x,s)] dx
$$
so
\begin{align*}
&\int_{|z| \le M_0} |V_k(g) - W(g)| dz  &\\
&\le \int_{|x| \le M_0} |g(x)| 
\int_{|z| \le M_0} \big| \big| K_k(x,s) - K_{\infty}(x,s)\big| dz dx &\\
&\le  
\int_{|x| \le M_0} |g(x)| dx
\sup_{|\xi| \le M_0 ((\frac{k}{k-1})^a -1)} \int \big| f_U\!(\xi + z ) -
f_U\!( z )| dz &
\end{align*}
thus,
$$
\| V_k - W\|_{Hom(L^1)} ~\le~ \sup_{|\xi| \le M_0 ((\frac{k}{k-1})^a -1)} \int \big| f_U\!(\xi + z ) -
f_U\!( z )| dz .
$$

Therefore, there is $\lambda_1 \in (0,1)$ and $k_0$ such that for any $g \in L^1[-M_0,M_0]$, if $\int g(x)dx = 0$, and $k \ge k_0$ then $\mathpzc{N}(V_k(g)) \le \lambda_1 \mathpzc{N}(g).$ 

Let $\Delta_k =  f_k - \phi_1 - (\int_{|x| \le M_0} f_k \ - \ 1)  = 
f_k - \phi_1 + (\int_{|x| > M_0} f_k) = f_k - \phi_1 + P(|Z_k| > M_0) $. We seek an inductive bound of $\Delta_{k}$. We are interest in the a bound for $f_k - \phi_1$, but in order to use the contraction property of $V_k$, we subtract a constant from $f_k - \phi_1$.  

\  

We have
\begingroup
\allowdisplaybreaks
\begin{align*}
&\Delta_{k+1} = f_{k+1}(z) - \phi_1(z) + \int_{|x| > M_0} f_{k+1}  &\\
&\ &\\
&= \int f_k(x) K_k(x,s) dx - \int \phi_1(x) K_{\infty}(x,s) dx + \int_{|x| > M_0} f_{k+1} &\\
&\ &\\
&= \int_{|x| \le M_0} \big(f_k(x) - \phi_1(x) \big) K_k(x,s) dx + \int_{|x| \le M_0} \phi_1(x) K_k(x,s) dx &\\
&\ &\\
&\quad \quad \quad +  \int_{|x| > M_0} f_k(x)  K_k(x,s) dx &\\
&\ &\\
&\quad \quad \quad - \int \phi_1(x) K_{\infty}(x,s) dx  + \int_{|x| > M_0} f_{k+1} &\\
&\ &\\
& = \int_{|x| \le M_0} \big(f_k(x) - \phi_1(x) \big) K_k(x,s) dx  &\\
&\ &\\
&\quad \quad \quad+  \int_{|x| > M_0} f_k(x)  K_k(x,s) dx &\\
&\ &\\
&\quad \quad \quad+ \int \phi_1(x) \big( K_k(x,s) - K_{\infty}(x,s) \big) dx &\\
&\ &\\
&\quad \quad \quad+ \int_{|x| > M_0} f_{k+1} &\\
&\ &\\
& = \int_{|x| \le M_0} \Delta_k(x) K_k(x,s) dx  &\\
&\ &\\
&\quad \quad \quad+  \big( \int_{|x| > M_0} f_{k} \big) \big( \int_{|x| \le M_0} K_k(x,s) dx \big) &\\
&\ &\\
&\quad \quad \quad+  \int_{|x| > M_0} f_k(x)  K_k(x,s) dx &\\
&\ &\\
&\quad \quad \quad+ \int \phi_1(x) \big( K_k(x,s) - K_{\infty}(x,s) \big) dx &\\
&\ &\\
&\quad \quad \quad+ \int_{|x| > M_0} f_{k+1} = I + II + III + IV + V &
\end{align*}
\endgroup
\  

We bound each term separately.  

\  

$I = \int_{|x| \le M_0} \Delta_k(x) K_k(x,s) dx = V_k( \Delta_k)$, so $\mathpzc{N}(I) \le \lambda_1 \mathpzc{N}(\Delta_k)$  

\  

$II = \big( \int_{|x| > M_0} f_{k} \big) \big( \int_{|x| \le M_0} K_k(x,s) dx \big) = P(|Z(k)| \ge M_0) W_k( I_{|x| \le M_0})$, so 
\begin{align*}
\int_{|z| \le M_0} II(z) dz &\le P(|Z(k)| \ge M_0) \int W_k( I_{|x| \le M_0}) &\\
&= P(|Z(k)| \ge M_0) \int I_{|x| \le M_0}) = 2\ M_0 P(|Z(k)| \ge M_0) &\\
&\le C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} k^{1-a} ) &
\end{align*}  

\  

$III = \int_{|x| > M_0} f_k(x)  K_k(x,s) dx = W_k( f_k I_{(|x| > M_0) } )$, therefore
$$
\int_{|z| \le M_0} III(z) dz \le \int  f_k I_{(|x| > M_0)} = P(|Z_k| \ge M_0) 
\le C\ exp( - \gamma_2 M_0^{(1-a)/a} k^{1-a} ).
$$  

\  

$IV = \int \phi_1(x) \big( K_k(x,s) - K_{\infty}(x,s) \big) dx $, terefore
\begin{align*}
\int_{|z| \le M_0} IV(z) dz  &\le  \int \phi_1(x) \int_{|z| \le M_0} \big| K_k(x,s) - K_{\infty}(x,s) \big| ds dx &\\
&\le \sup_{|\xi| \le M_0 ( (\frac{k}{k-1})^a -1)} 
\int \big| f_U(\xi+s) - f_U(s) \big| ds. &
\end{align*}  

\  

$V = \int_{|x| > M_0} f_{k+1} = P(|Z_{k+1}| \ge M_0) 
\le C\ exp( - \gamma_2 M_0^{(1-a)/a} (k+1)^{1-a} )$, therefore
$$
\int_{|z| \le M_0} V(z) dz \le C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} (k+1)^{1-a} )
$$  

\  

Putting all these five inequalities together, using the equivalence of $\mathpzc{N}$ and the usual $L^1$ norm, we get ($C$ represents a constant, not allways the same from occurrence to occurrence)
$$
\begin{aligned}
&\mathpzc{N}(\Delta_{k+1}) \le \lambda_1 \mathpzc{N}(\Delta_k) + C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} k^{1-a} ) &\\
&\  + C \sup_{|\xi| \le M_0 ( (\frac{k}{k-1})^a -1)} \int \big| f_U(\xi+s) - f_U(s) \big| ds  
+ C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} (k+1)^{1-a} &\\
& \le \lambda_1 \mathpzc{N}(\Delta_k) + C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} k^{1-a} ) &\\
&\  + C \sup_{|\xi| \le M_0 ( (\frac{k}{k-1})^a -1)} \int \big| f_U(\xi+s) - f_U(s) \big| ds  &\\
& = \lambda_1 \mathpzc{N}(\Delta_k) + \epsilon_k &
\end{aligned}  
$$  
where 
$$\epsilon_k = C\ M_0 exp( - \gamma_2 M_0^{(1-a)/a} k^{1-a} )
  + C \sup_{|\xi| \le M_0 ( (\frac{k}{k-1})^a -1)} \int \big| f_U(\xi+s) - f_U(s) \big| ds \rightarrow 0
 $$  

\  

Thus, we have obtained an inequality of the form $A_{k+1} \le \lambda_1 A_k + \epsilon_k $, with $0 < \lambda_1 < 1$, and $\epsilon_k \rightarrow 0$. This implies that $A_k \rightarrow 0$. Indeed, consider that,
$$
\frac{A_{k+1}}{\lambda_1^{k+1}} ~\le~ \frac{A_{k}}{\lambda_1^{k}} + \frac{\epsilon_{k}}{\lambda_1^{k+1}}
$$
so, for $q < p$:
$$
\frac{A_p}{\lambda_1^p} ~\le~ \frac{A_q}{\lambda_1^q} + \sum_{j=q}^{p-1} \frac{\epsilon_{j}}{\lambda_1^{j+1}}
$$
then
$$
\begin{aligned}
& A_p &~\le~& \lambda_1^p \frac{A_q}{\lambda_1^q} + \sum_{j=q}^{p-1} \epsilon_j \lambda_1^{p-j-1} \\
&\  &~\le~& \lambda_1^p \frac{A_q}{\lambda_1^q} 
+ \sup_{j \ge q} \epsilon_j  \sum_{j=q}^{p-1} \lambda_1^{p-j-1} \\
&\  &~\le& \lambda_1^p \frac{A_q}{\lambda_1^q} 
+ \sup_{j \ge q} \epsilon_j  \sum_{j=0}^{\infty} \lambda_1^{j} \\
&\  &~=~& \lambda_1^p \frac{A_q}{\lambda_1^q} 
+ \sup_{j \ge q} \epsilon_j  \frac{1}{1-\lambda_1}.
\end{aligned}
$$
so $ \int_{|z| \le M_0} |\Delta_p(z)| dz \rightarrow 0$ as $p \rightarrow \infty$.  

\ 

Now part $d)$ is trivial:
$$
\int |f_k - \phi_1| = \int_{|z| \le M_0} |f_k - \phi_1|  + \int_{|z| > M_0}  |f_k - \phi_1|
$$
but $\phi_1$ is supported on $[-1,1]$, so $\int_{|z| > M_0}  |f_k - \phi_1| = \int_{|z| > M_0}  f_k = P(|Z_k| > M_0) \rightarrow 0$ as $k \rightarrow \infty$,
and
\begin{align*}
&\int_{|z| \le M_0} |f_k - \phi_1| = \int_{|z| \le M_0} |\Delta_k - P(|Z_k| > M_0)| \\
&\le \int_{|z| \le M_0} |\Delta_k|  + 2M_0\ P(|Z_k| > M_0) \rightarrow 0
\end{align*}
\end{proof}

\  

\  

\  

\begin{lemma}
	Part $f)$ of the Theorem stated in the Section \ref{sec:intro} holds.
\end{lemma}
\begin{proof}
Part $f)$ is a simple consequence of $d)$. For any Borel set $B \subset \mathbb{R}$, $P(Z_k \in B) = \int_B f_k \rightarrow  \int_B \phi_1 = P(Z \in B)$. 
\end{proof}


\  

\  

\  

\begin{lemma}
	Part $e)$ of the Theorem stated in the Section \ref{sec:intro} holds.
\end{lemma}
\begin{proof}
Let $f_U \in L^{p}([0,1])$ for some $p>1$. Choose $N$ minimal positive integer such that $p  \ge 1 + \frac{1}{N-1}$. Since $f_U \in L^1([0,1])$, then $f_U \in L^{p_1}([0,1])$ where $\frac{1}{p_1} = 1 - \frac{1}{N}$.

We claim that for $j=1,\dots , N$, $f_j$, the probability density function of $Z_j$, is in $L^{p_j}$ where $\frac{1}{p_j} = 1 - \frac{j}{N}$. Indeed, $Z_1 = -U_1$, so $f_1(s) = f_U(-s) \in L^{p_1}$ by assumption. Now we proceed inductively. If $f_j  \in L^{p_j}$ for some $1 \le j < N$, then $f_{j+1} = W_{j+1}(f_j)$. Recall $W_{j+1}$ can be written as in (\ref{eq:Wk_Lp}) in terms of convolutions, so $ f_{j+1} = A_{j+1}(f_j)*f_U + B_{j+1}(f_j)*\mathcal{O}(f_U)$. We apply Young's inequality to conclude $\|f_{j+1}\|_r \le C \|f_j\|_{p_j} \|f_U\|_{p_1}$ where  
$$
\frac{1}{r} ~=~ \frac{1}{p_j} + \frac{1}{p_1} - 1 ~=~ 1 - \frac{j}{N} + 1 - \frac{1}{N} -1 ~=~ 1 - \frac{j+1}{N}
$$ 
which completes the induction.  

In particular, when $j=N$ we get $\|f_j\|_{\infty} \le C \|f_U\|_{p_1}^j$ for a constant $C$ that only depends on $p_1$.  

For $j=N+1,\dots$, $\|f_j\|_{infty} = \|W_j(f_{j-1})\|_{infty} \le \|f_{j-1}\|_{infty}$, thus, the family $\{f_j\}_{j>N}$ is uniformly bounded. Moreover, the family is equicontinuous on compact subsets of $\mathbb{R}$, the continuity modulus dominated by the $L^1$ continuity modulus of $f_U$. Therefore the family is relatively compact on intervals, and since it converges in $L^1$ to $\phi_1$, it converges to $\phi_1$ uniformly on any baunded interval. To show convergence over the entire line we need only uniform bounds of the tails.  

\  

Let $M_0$ as in Lemma \ref{lm:XZ convrgnce}. For $j > N$, and $ |z| > 3 M_0$ we have
\begin{align*}
0 \le f_j(z) &= \int f_{j-1}(x) f_U\!\big( (x \rho_j - z)sign(x)  \big) dx &\\
&\  &\\
&=\int_{|x-z|\le 1} \rho_j^{-1} f_{j-1}(\rho_j^{-1}x) f_U\!\big( (x - z)sign(x)  \big) dx & \\
&\  &\\
& \le \left( \int_{|x-z|\le 1} \left[ \rho_j^{-1} f_{j-1}(\rho_j^{-1}x) \right]^{q_1}  dx \right)^{\frac{1}{q_1}} 
\left( \int  f_U\!\big( t  \big)^{p_1} dt \right)^{\frac{1}{p_1}} &
\end{align*}
where we wrote $\rho_j$ for $ \left( \frac{j}{j-1}\right)^a$ to simplify the notation, and $\frac{1}{q_1} ~=~ 1 - \frac{1}{p_1} ~=~ \frac{1}{N}$, so $q_1=N$.  

\

In the integral, $|x-z| \le 1$, so $|x| \ge |z| - 1 \ge 3 M_0 - 1 > 2 M_0$, then
\begin{align*}
&\left( \int_{|x-z|\le 1} \left[ \rho_j^{-1} f_{j-1}(\rho_j^{-1}x) \right]^{q_1} dx \right)^{\frac{1}{q_1}} &\\
&\ &\\
&\  \le 
\Bigg( \rho_j^{-1} \|f_{j-1}\|_{\infty} \Bigg)^{\frac{N-1}{N}} 
\left(  \int_{|x|\ge \rho_j^{-1} 2 M_0} f_{j-1}(x) dx \right)^{\frac{1}{N}} \\
&\ &\\
&\le \|f_{N}\|_{\infty}^{\frac{N-1}{N}} P(|Z_{j-1}| \ge \rho_j^{-1} 2 M_0)^{\frac{1}{N}} &\\
&\ &\\
&~\le~ C \|f_{N}\|_{\infty}^{\frac{N-1}{N}} exp\left(-\gamma_5 M_0^{\frac{1-a}{a} } j^{1-a} \right)&
\end{align*}
where we made use of $\rho_j^{-1} < 1$, $\|f_{j}\|_{\infty} \le \|f_{N}\|_{\infty}$ for $j \ge N$, the bound for the tail probability of $Z_{j-1}$ given in Lemma \ref{lm:XZ convrgnce}, $C$ and $\gamma_5$ are constants that depend only on $p_1, a$ and $\mu = E( U_1)$.  

\  

There $f_j \rightarrow 0$ uniformly in the complement of $[-3M_0, 3M_0]$

\end{proof}




\end{section}



\  
  

REFERENCES  

TBC

\end{document}